import os
import time
import re
import bs4
import pillow_heif
import numpy as np
from datetime import datetime
import hashlib
import mimetypes
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont, ImageOps
from pillow_heif import register_heif_opener
import io
import math
import textwrap
import zipfile
import bz2
import gzip
from bs4 import BeautifulSoup
from qr_code_generator import create_qr_code

try:
    from fitparse import FitFile
    FITPARSE_AVAILABLE = True
except ImportError:
    FITPARSE_AVAILABLE = False
import binascii
import json
from pdf2image import convert_from_path
import gpxpy
import cv2

# Patch for Python 3.13 compatibility
import collections
if not hasattr(collections, 'MutableMapping'):
    import collections.abc
    collections.MutableMapping = collections.abc.MutableMapping

import requests
import dotenv
import polyline
import logging
import traceback
import random
from pillow_textbox import draw_text_box

Image.MAX_IMAGE_PIXELS = 500_000_000  # or any large number
#Image.MAX_IMAGE_PIXELS = None  # disables the limit (use with caution)

register_heif_opener()


# Initialize mimetypes
mimetypes.init()

dotenv.load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s:%(levelname)s - %(name)s %(filename)s@%(lineno)d - %(message)s'
)

# Allow optional global Slack export root (can be set by create_file_cards.py or via env SLACK_DATA_DIR)
slack_data_root = None
# _env_slack = os.getenv("SLACK_DATA_DIR") or os.getenv("SLACK_ROOT")
# if _env_slack:
#     try:
#         SLACK_DATA_ROOT = Path(_env_slack).expanduser().resolve()
#     except Exception:
#         SLACK_DATA_ROOT = None

logging.getLogger("pdf2image").setLevel(logging.WARNING)
logging.getLogger("PIL").setLevel(logging.WARNING)
logging.getLogger("matplotlib").setLevel(logging.WARNING)
logging.getLogger("img2pdf").setLevel(logging.WARNING)

# Try to import fontTools for font metadata
try:
    from fontTools import ttLib
    FONTTOOLS_AVAILABLE = True
except ImportError:
    FONTTOOLS_AVAILABLE = False
    logging.warning("fontTools not available. Font metadata will be limited.")


def wrap_text_by_pixel(draw, text, font, max_width):
    if text == "":
        return [""]
    words = text.split()
    lines = []
    current_line = ""
    for word in words:
        test_line = current_line + (" " if current_line else "") + word
        bbox = draw.textbbox((0, 0), test_line, font=font)
        line_width = bbox[2] - bbox[0]
        if line_width <= max_width:
            current_line = test_line
        else:
            if current_line:
                lines.append(current_line)
            # If the word itself is too long, break it up
            while True:
                word_bbox = draw.textbbox((0, 0), word, font=font)
                word_width = word_bbox[2] - word_bbox[0]
                if word_width <= max_width:
                    current_line = word
                    break
                # Find the largest substring of word that fits
                for i in range(len(word), 0, -1):
                    part = word[:i]
                    part_bbox = draw.textbbox((0, 0), part, font=font)
                    part_width = part_bbox[2] - part_bbox[0]
                    if part_width <= max_width:
                        lines.append(part)
                        word = word[i:]
                        break
                else:
                    # If no part fits (very small max_width), forcibly break one character
                    lines.append(word[0])
                    word = word[1:]
                if not word:
                    current_line = ""
                    break
    if current_line:
        lines.append(current_line)
    return lines

def round_image_corners(img, radius):
    # Ensure img is RGBA
    img = img.convert("RGBA")
    w, h = img.size
    # Create mask
    mask = Image.new("L", (w, h), 0)
    draw = ImageDraw.Draw(mask)
    draw.rounded_rectangle([0, 0, w, h], radius=radius, fill=255)
    # Apply mask
    img.putalpha(mask)
    return img

def scale_image(image, scale_factor):
    """Scale a PIL image by a given scale factor (e.g., 0.95 for 95%)."""
    if image is None or scale_factor <= 0:
        return None
    w, h = image.size
    new_w = max(1, int(w * scale_factor))
    new_h = max(1, int(h * scale_factor))
    return image.resize((new_w, new_h), Image.LANCZOS)

# Define file type groups with recognizable icons
FILE_TYPE_GROUPS = {
    'code': {
        'extensions': {'.patch', '.py', '.js', '.html', '.css', '.java', '.c', '.cpp', '.h', '.sh', '.rb', '.swift', '.php', '.go'},
        'icon': "< / >",
        'color': (251, 64, 55)  # HEX: fb4037
    },
    'data': {
        'extensions': {'.json', '.csv', '.xml', '.yaml', '.yml', '.toml', '.ini'},
        'icon': "{ }",
        'color': (210, 255, 66)  # HEX: d2ff42
    },
    'spreadsheet': {
        'extensions': {'.xlsx', '.xls', '.numbers'},
        'icon': "SPREADSHEET",
        'color': (255, 93, 153)  # HEX: 686974
    },
    'document': {
        'extensions': {'.doc', '.docx','.odt','.tex'},
        'icon': "DOC",
        'color': (123, 17, 116)  # HEX: 6b6d67
    },
    'pdf': {
        'extensions': {'.pdf'},
        'icon': "PDF",
        'color': (69, 137, 119)  # HEX: 458977
    },
    'presentation': {
        'extensions': {'.ppt', '.pptx', '.odp', '.key'},
        'icon': "DECK OF SLIDES",
        'color': (166, 0, 245)  # HEX: #a600f5
    },
    'text': {
        'extensions': {'.txt', '.md', '.rtf', '.mdx'},
        'icon': "TEXT",
        'color': (101, 0, 237)  # HEX: 6500ed
    },
    'archive': {
        'extensions': {'.zip', '.tar', '.gz', '.bz2', '.rar', '.7z'},
        'icon': "ZIP",
        'color': (128, 128, 38)  # HEX: 808026
    },
    'executable': {
        'extensions': {'.exe', '.bin', '.app', '.sh', '.bat', '.dll', '.so', '.dylib'},
        'icon': "EXE",
        'color': (0, 0, 0)  # HEX: 000000
    },
    'binary': {
        'extensions': {'.hex', '.bin', '.dat', '.dfu', '.oci'},
        'icon': "BIN",
        'color': (252, 252, 75)  # HEX: fcfc4a
    },
    'font': {
        'extensions': {'.ttf', '.otf', '.woff', '.woff2', '.eot'},
        'icon': "FONT",
        'color': (34, 153, 84)  # HEX: #229954
    },
    'gps': {
        'extensions': {'.gpx', '.fit', '.tcx'},
        'icon': "GPS",
        'color': (123, 156, 116)  # HEX: 33A1FD
    },
    'log': {
        'extensions': {'.log', '.txt', '.out'},
        'icon': "LOG",
        'color': (0, 0, 0)  # HEX: 000000
    },
    'movie': {
        'extensions': {'.mp4', '.mkv', '.avi', '.mov', '.m4v', '.webm'},
        'icon': "MOVIE",
        'color': (42, 219, 61)  # HEX: 2adb3d
    },
    'image': {
        'extensions': {'.jpg', '.jpeg', '.png','.bmp', '.tif', '.tiff', '.webp'},
        'icon': "IMAGE",
        'color': (0, 136, 255)  # HEX: 0088FF
    },
    'animated': {
        'extensions': {'.gif'},
        'icon': "ANIMATED",
        'color': (255, 126, 54)  # HEX: ff7e36
    },
    'cad': {
        'extensions': {'.stp', '.step', '.igs', '.iges', '.stl', '.dxf', '.obj'},
        'icon': "CAD",
        'color': (45, 150, 230)  # HEX: 2D96E6
    }
}

SPECIAL_METADATA_DIRECT_VALUE_KEYS = {"name", "filename", "filepath", "created"}

def scale_image_by_percent(image, percent):
    """Scale a PIL image by a given percentage (e.g., percent=0.95 for 95%)."""
    if image is None or percent <= 0:
        return None
    w, h = image.size
    new_w = max(1, int(w * percent))
    new_h = max(1, int(h * percent))
    return image.resize((new_w, new_h), Image.LANCZOS)

def get_file_type_info(file_path):
    """Determine file type group and icon information."""
    ext = file_path.suffix.lower()
    #logging.debug(f"ext={ext}")
    # Check if the extension is in any of our groups
    for group, info in FILE_TYPE_GROUPS.items():
        if ext in info['extensions']:
            #logging.debug(f"Found group {group} for extension {ext} for file {file_path}")
            return {
                'group': group,
                'icon': info['icon'],
                'color': info['color']
            }
    # If not found, try to use mimetype to determine a general type
    mime_type, _ = mimetypes.guess_type(str(file_path))
    if mime_type:
        if mime_type.startswith('text/'):
            return {
                'group': 'text',
                'icon': "TXT",
                'color': (216, 71, 151)  #  
            }
        elif mime_type.startswith('application/'):
            return {
                'group': 'application',
                'icon': "APP",
                'color': (238, 97, 35)  # Darker red
            }
    # Default for unknown types
    return {
        'group': 'unknown',
        'icon': "FILE",
        'color': (250, 0, 63)  # Medium gray
    }

def format_file_size(size_bytes):
    """Format file size in human-readable format."""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    elif size_bytes < 1024 * 1024 * 1024:
        return f"{size_bytes / (1024 * 1024):.1f} MB"
    else:
        return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"

def get_file_hash(file_path, algorithm='md5', block_size=65536):
    """Calculate hash of file contents."""
    hash_obj = hashlib.new(algorithm)
    with open(file_path, 'rb') as f:
        for block in iter(lambda: f.read(block_size), b''):
            hash_obj.update(block)
    return hash_obj.hexdigest()[:10]  # First 10 chars for brevity


def preview_html_content(file_path, max_lines=5, max_line_length=40):
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            html = f.read()
        soup = BeautifulSoup(html, "html.parser")
        text = soup.get_text(separator="\n")
        lines = []
        for i, line in enumerate(text.splitlines()):
            if i >= max_lines:
                break
            wrapped = textwrap.wrap(line.strip(), width=max_line_length)
            if not wrapped:
                lines.append('')
            else:
                lines.extend(wrapped)
        return lines
    except Exception:
        return None

def preview_text_content(file_path, max_lines=5, max_line_length=40):
    """Get a preview of text content if the file is text-based, wrapping long lines."""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = []
            for i, line in enumerate(f):
                if i >= max_lines:
                    break
                wrapped = textwrap.wrap(line.rstrip('\n'), width=max_line_length)
                if not wrapped:
                    lines.append('')
                else:
                    lines.extend(wrapped)
            return lines
    except Exception:
        return None

def get_original_timestamp(file_path):
    """Try to find the original timestamp for a file from messages.json in the parent directory."""
    parent = file_path.parent
    messages_json = slack_data_root / "messages.json"
    if not messages_json.exists():
        return None
    try:
        with open(messages_json, 'r', encoding='utf-8', errors='ignore') as f:
            messages = json.load(f)
        for msg in messages:
            if 'files' in msg:
                for fobj in msg['files']:
                    # Match by filename
                    if fobj.get('name') == file_path.name:
                        # Prefer human-readable timestamp if available
                        ts_human = msg.get('ts_human') or fobj.get('ts_human')
                        if ts_human:
                            try:
                                # Try to parse as datetime
                                return datetime.strptime(ts_human, "%Y-%m-%d %H:%M:%S")
                            except Exception:
                                return ts_human  # Return as string if parsing fails
                        ts = fobj.get('timestamp') or fobj.get('created') or msg.get('ts')
                        if ts:
                            try:
                                return datetime.fromtimestamp(float(ts))
                            except Exception:
                                pass
        return None
    except Exception:
        return None

def get_zip_preview(file_path, max_files=40):
    try:
        with zipfile.ZipFile(file_path, 'r') as z:
            names = z.namelist()
            if len(names) == 1:
                # If only one file, extract and show hex preview
                with z.open(names[0]) as f:
                    data = f.read(1024)
                hex_lines = []
                for i in range(0, len(data), 16):
                    chunk = data[i:i+16]
                    hexstr = ' '.join(f"{b:02X}" for b in chunk)
                    ascii_str = ''.join(chr(b) if 32 <= b < 127 else '.' for b in chunk)
                    hex_lines.append(f"{i:08X}: {hexstr:<48} {ascii_str}")
                return [f"ZIP: 1 file ({names[0]})"] + hex_lines
            # More than one file: list all, then hex dump largest
            file_infos = [(name, z.getinfo(name).file_size) for name in names]
            file_infos.sort(key=lambda x: x[1], reverse=True)
            largest_name, largest_size = file_infos[0]
            with z.open(largest_name) as f:
                data = f.read(1024)
            hex_lines = []
            for i in range(0, len(data), 16):
                chunk = data[i:i+16]
                hexstr = ' '.join(f"{b:02X}" for b in chunk)
                ascii_str = ''.join(chr(b) if 32 <= b < 127 else '.' for b in chunk)
                hex_lines.append(f"{i:08X}: {hexstr:<48} {ascii_str}")
            listing = [f"ZIP: {len(names)} files"] + [f"  {name} ({size} bytes)" for name, size in file_infos[:max_files]]
            listing.append(f"\nLargest file: {largest_name} ({largest_size} bytes) hex preview:")
            return listing + hex_lines
    except Exception as e:
        return [f"ZIP error: {e}"]

def get_bz2_preview(file_path, max_bytes=1024):
    try:
        with bz2.open(file_path, 'rb') as f:
            data = f.read(max_bytes)
        hex_lines = []
        for i in range(0, len(data), 16):
            chunk = data[i:i+16]
            hexstr = ' '.join(f"{b:02X}" for b in chunk)
            ascii_str = ''.join(chr(b) if 32 <= b < 127 else '.' for b in chunk)
            hex_lines.append(f"{i:08X}: {hexstr:<48} {ascii_str}")
        return ["BZ2 (hex preview):"] + hex_lines
    except Exception as e:
        return [f"BZ2 error: {e}"]

def get_gz_preview(file_path, max_bytes=1024, preview_box=None):
    import mimetypes
    try:
        with gzip.open(file_path, 'rb') as f:
            data = f.read(max_bytes * 10)  # Read more for image/text detection
        # Guess file type from original filename if possible
        orig_name = Path(file_path).stem
        ext = Path(orig_name).suffix.lower()
        # Try image preview
        if ext in {'.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff', '.heic', '.heif','.webp'} and preview_box:
            try:
                img = Image.open(io.BytesIO(data))
                img.thumbnail(preview_box)
                return None, img, None
            except Exception:
                pass
        # Try text preview
        mime, _ = mimetypes.guess_type(orig_name)
        if mime and mime.startswith('text'):
            try:
                text = data.decode(errors='ignore')
                lines = text.splitlines()[:40]
                return lines, None, None
            except Exception:
                pass
        # Fallback: hex preview
        hex_lines = []
        for i in range(0, min(len(data), max_bytes), 16):
            chunk = data[i:i+16]
            hexstr = ' '.join(f"{b:02X}" for b in chunk)
            ascii_str = ''.join(chr(b) if 32 <= b < 127 else '.' for b in chunk)
            hex_lines.append(f"{i:08X}: {hexstr:<48} {ascii_str}")
        return hex_lines, None, None
    except Exception as e:
        return [f"GZ error: {e}"], None, None

def is_mostly_text_or_html(file_path, chunk_size=4096):
    try:
        with open(file_path, 'rb') as f:
            chunk = f.read(chunk_size)
        try:
            text = chunk.decode('utf-8')
        except UnicodeDecodeError:
            text = chunk.decode('latin-1')
        printable = sum(c.isprintable() or c.isspace() for c in text)
        ratio = printable / max(1, len(text))
        html_like = any(tag in text.lower() for tag in ['<html', '<body', '<div', '<span', '<head', '<title', '<p>'])
        # Consider as text if >90% printable or contains HTML tags
        return ratio > 0.9 or html_like
    except Exception:
        return False


def get_hex_preview(file_path, max_bytes=1024):
    try:
        with open(file_path, 'rb') as f:
            data = f.read(max_bytes)
        hex_lines = []
        for i in range(0, len(data), 16):
            chunk = data[i:i+16]
            hexstr = ' '.join(f"{b:02X}" for b in chunk)
            ascii_str = ''.join(chr(b) if 32 <= b < 127 else '.' for b in chunk)
            hex_lines.append(f"{i:08X}: {hexstr:<48} {ascii_str}")
        return hex_lines
    except Exception as e:
        return [f"Hex error: {e}"]

def get_fit_preview(file_path, max_records=40):
    if not FITPARSE_AVAILABLE:
        return ["fitparse not installed"]
    try:
        fitfile = FitFile(str(file_path))
        lines = []
        for i, record in enumerate(fitfile.get_messages()):
            if i >= max_records:
                break
            lines.append(f"{record.get('name', 'Record')}: {record}")
        if not lines:
            lines = ["No records found"]
        return lines
    except Exception as e:
        return [f"FIT error: {e}"]

def get_fit_summary_preview(file_path):
    if not FITPARSE_AVAILABLE:
        return ["fitparse not installed"], {}
    try:
        fitfile = FitFile(str(file_path))
        summary = []
        meta = {}
        # Try to extract session/activity summary
        for msg in fitfile.get_messages('session'):
            fields = {d.name: d.value for d in msg}
            summary.append(f"Session: {fields.get('sport', 'N/A')} {fields.get('sub_sport', '')}")
            if 'start_time' in fields:
                summary.append(f"Start: {fields['start_time']}")
                meta['start_time'] = fields['start_time']
            if 'total_timer_time' in fields:
                summary.append(f"Duration: {fields['total_timer_time']:.1f} sec")
            if 'total_distance' in fields:
                summary.append(f"Distance: {fields['total_distance']/1000:.2f} km")
            if 'total_ascent' in fields:
                summary.append(f"Ascent: {fields['total_ascent']} m")
            if 'avg_speed' in fields:
                summary.append(f"Avg Speed: {fields['avg_speed']*3.6:.2f} km/h")
            if 'max_speed' in fields:
                summary.append(f"Max Speed: {fields['max_speed']*3.6:.2f} km/h")
            if 'total_calories' in fields:
                summary.append(f"Calories: {fields['total_calories']}")
            summary.append("")
        # If no session, try activity
        if not summary:
            for msg in fitfile.get_messages('activity'):
                fields = {d.name: d.value for d in msg}
                summary.append(f"Activity: {fields.get('type', 'N/A')}")
                if 'timestamp' in fields:
                    summary.append(f"Timestamp: {fields['timestamp']}")
                    meta['timestamp'] = fields['timestamp']
                summary.append("")
        # GPS points summary
        gps_points = []
        for record in fitfile.get_messages('record'):
            lat = None
            lon = None
            for d in record:
                if d.name == 'position_lat':
                    lat = d.value
                elif d.name == 'position_long':
                    lon = d.value
            if lat is not None and lon is not None:
                lat = lat * (180.0 / 2**31)
                lon = lon * (180.0 / 2**31)
                gps_points.append((lat, lon))
        if gps_points:
            summary.append(f"GPS Points: {len(gps_points)}")
            summary.append(f"Start: ({gps_points[0][0]:.5f}, {gps_points[0][1]:.5f})")
            summary.append(f"End:   ({gps_points[-1][0]:.5f}, {gps_points[-1][1]:.5f})")
            # Optionally show a few sample points
            if len(gps_points) > 2:
                summary.append(f"Sample: ({gps_points[len(gps_points)//2][0]:.5f}, {gps_points[len(gps_points)//2][1]:.5f})")
        # Fallback: show number of records
        n_records = sum(1 for _ in fitfile.get_messages('record'))
        summary.append(f"Records: {n_records}")
        meta['records'] = n_records
        # Add all metadata fields from file header
        if hasattr(fitfile, 'file_id'):
            for k, v in fitfile.file_id.items():
                summary.append(f"{k}: {v}")
                meta[k] = v
        return summary[:40], meta
    except Exception as e:
        return [f"FIT error: {e}"], {}

def get_pdf_preview(file_path, box_w, box_h):
    try:
        # First, get the total number of pages
        from pdf2image import convert_from_path
        #import numpy as np
        #logging.debug(f"Attempting to extract PDF preview: {file_path}")
        all_pages = convert_from_path(str(file_path))
        n_total = len(all_pages)
        logging.info(f"PDF {file_path} page count is {n_total} pages")

        if n_total == 0:
            logging.warning(f"No pages found in PDF: {file_path}")
            return None

        # Cap how many pages we consider for previews to avoid extreme CPU and tiny thumbs
        max_preview_cap = min(n_total, 42)

        best_score = -1
        best_config = None

        # Try all candidate preview counts (1..max_preview_cap)
        for total_count in range(1, max_preview_cap + 1):
            # Choose evenly distributed page indices for this total_count (always include first page)
            indices = [0]
            if total_count > 1 and n_total > 1:
                remaining = np.linspace(1, n_total - 1, total_count - 1)
                indices += [int(round(i)) for i in remaining]
            indices = sorted(set(indices))
            selected_pages = [all_pages[i] for i in indices]
            n_pages = len(selected_pages)

            # Evaluate every possible rows partition for this selection
            for rows in range(1, n_pages + 1):
                cols = int(math.ceil(n_pages / rows))
                cell_w = box_w // cols
                cell_h = box_h // rows

                # Ignore impossible cells
                if cell_w <= 0 or cell_h <= 0:
                    continue

                total_used_area = 0
                orientations = []  # True if rotated for best fit, False otherwise

                # For each page, try both orientations and pick the one that uses more area in the cell
                for page in selected_pages:
                    w, h = page.width, page.height

                    # No-rotate fit
                    scale_no = min(cell_w / w, cell_h / h) if w and h else 0
                    used_w_no = int(max(0, int(w * scale_no)))
                    used_h_no = int(max(0, int(h * scale_no)))
                    area_no = used_w_no * used_h_no

                    # Rotated fit (90 degrees)
                    scale_rot = min(cell_w / h, cell_h / w) if w and h else 0
                    used_w_rot = int(max(0, int(h * scale_rot)))
                    used_h_rot = int(max(0, int(w * scale_rot)))
                    area_rot = used_w_rot * used_h_rot

                    if area_rot > area_no:
                        total_used_area += area_rot
                        orientations.append(True)
                    else:
                        total_used_area += area_no
                        orientations.append(False)

                # Keep the configuration with the highest total used thumbnail area
                score = total_used_area + n_pages * 10000  # Bonus: 10,000 per page shown

                if score > best_score:
                    best_score = score
                    best_config = {
                        'indices': indices,
                        'rows': rows,
                        'cols': cols,
                        'cell_w': cell_w,
                        'cell_h': cell_h,
                        'selected_pages': selected_pages,
                        'orientations': orientations
                    }

        if not best_config:
            logging.warning(f"Could not determine a layout for PDF: {file_path}")
            return None

        # Build thumbnails using the chosen layout and orientations
        selected_pages = best_config['selected_pages']
        best_rows = best_config['rows']
        best_cols = best_config['cols']
        best_thumb_w = best_config['cell_w']
        best_thumb_h = best_config['cell_h']
        orientations = best_config['orientations']

        thumbs = []
        for page, rotate_choice in zip(selected_pages, orientations):
            page = page.copy()
            if rotate_choice:
                page = page.rotate(90, expand=True)
            # Scale the page to fit the cell while preserving aspect ratio
            try:
                thumb = ImageOps.contain(page, (best_thumb_w, best_thumb_h), Image.LANCZOS)
            except Exception:
                # Fallback to thumbnail if ImageOps is not available for some reason
                thumb = page.copy()
                thumb.thumbnail((best_thumb_w, best_thumb_h))
            thumbs.append(thumb)
        grid_img = Image.new('RGB', (box_w, box_h), (255, 255, 255))
        for idx, page in enumerate(thumbs):
            # Default row-major placement: left-to-right, top-to-bottom
            if not orientations[idx]:
                col = idx % best_cols
                row = idx // best_cols
            else:
                # For rotated pages, fill columns left-to-right, each column bottom-to-top
                # This preserves the natural reading order when pages are rotated 90 degrees.
                col = idx // best_rows
                row_in_col = idx % best_rows
                row = best_rows - 1 - row_in_col
            x = col * best_thumb_w + (best_thumb_w - page.width) // 2
            y = row * best_thumb_h + (best_thumb_h - page.height) // 2
            grid_img.paste(page, (x, y))

        return grid_img
    except Exception as e:
        logging.error(f"PDF preview error for {file_path}: {e}")
        return None

def get_image_thumbnail(file_path, box_size=(320, 320), cmyk_mode=False):
    try:
        img = Image.open(file_path)
        # Composite transparent images onto white/light background BEFORE any CMYK conversion
        if img.mode in ("RGBA", "LA"):
            #logging.debug(f"Compositing transparent image onto white background: {file_path.name}")
            background = Image.new("RGBA", img.size, (250, 250, 250))
            background.paste(img, mask=img.split()[-1])
            img = background

        img_w, img_h = img.size
        box_w, box_h = box_size
        # Rotate image if box is portrait and image is landscape
        if box_h > box_w and img_w > img_h:
            img = img.rotate(90, expand=True)
            img_w, img_h = img.size
        # Scale to fit box, maximizing coverage
        scale_factor = min(box_w / img_w, box_h / img_h)
        new_w = int(img_w * scale_factor)
        new_h = int(img_h * scale_factor)
        img = img.resize((new_w, new_h), Image.LANCZOS)
        # Center in box

        # Set the background color behind the image thumbnail
        if cmyk_mode:
            # Use CMYK equivalent of light gray
            thumb_bg_color = rgb_to_cmyk(250, 250, 250)
            thumb = Image.new('CMYK', (box_w, box_h), thumb_bg_color)
        else:
            thumb = Image.new('RGB', (box_w, box_h), (250, 250, 250))

        x = (box_w - new_w) // 2
        y = (box_h - new_h) // 2
        thumb.paste(img, (x, y))
        return thumb
    except Exception:
        return None

def get_font_preview(file_path, box_w, box_h):
    """
    Generate a preview image for a font file (TTF, OTF).
    
    Args:
        file_path: Path to the font file
        box_w: Width of the preview box
        box_h: Height of the preview box
        
    Returns:
        A PIL Image containing a preview of the font with sample text
    """
    try:
        # Create a white background image
        preview = Image.new('RGB', (box_w, box_h), (255, 255, 255))
        draw = ImageDraw.Draw(preview)
        
        # Try to load the font
        font_path = str(file_path)
        
        # Sample text to display
        sample_text = "The OMATA One. As useful as art."
        pangram = "The quick brown fox jumps over the lazy dog"
        numbers = "0123456789"
        special_chars = "!@#$%^&*()_+-=[]{}|;:'\",.<>/?"
        
        # Font sizes to display
        # Font sizes to display
        sizes = [36, 48, 64, 72]
        
        # Get font metadata if possible
        font_metadata = []
        if FONTTOOLS_AVAILABLE:
            try:
                font = ttLib.TTFont(font_path)
                
                # Try to get font family name
                if 'name' in font:
                    for record in font['name'].names:
                        if record.nameID == 1 and record.isUnicode():  # Font Family name
                            family_name = record.toUnicode()
                            font_metadata.append(f"Family: {family_name}")
                            break
                    
                    for record in font['name'].names:
                        if record.nameID == 2 and record.isUnicode():  # Font Subfamily name
                            style = record.toUnicode()
                            font_metadata.append(f"Style: {style}")
                            break
                            
                    for record in font['name'].names:
                        if record.nameID == 5 and record.isUnicode():  # Version
                            version = record.toUnicode()
                            font_metadata.append(f"Version: {version}")
                            break
            except Exception as e:
                logging.error(f"Could not read font metadata: {e}")
        
        if not font_metadata:
            font_metadata = ["Font: " + os.path.basename(font_path)]
        
        # Draw font metadata
        # Use a much larger font for metadata
        big_metadata_font_size = max(24, int(box_h * 0.02))
        try:
            metadata_font = ImageFont.truetype(font_path, big_metadata_font_size)
        except Exception:
            metadata_font = ImageFont.load_default()
        y_pos = 10
        for line in font_metadata:
            draw.text((10, y_pos), line, fill=(0, 0, 0), font=metadata_font)
            # Increase spacing for big font
            y_pos += big_metadata_font_size + 10
        
        y_pos += 20  # Extra space after metadata
        
        # Draw sample text in different sizes
        for size in sizes:
            try:
                font = ImageFont.truetype(font_path, size)
                text = f"{size}pt: {sample_text}"
                draw.text((10, y_pos), text, fill=(0, 0, 0), font=font)
                y_pos += size + 60
            except Exception as e:
                logging.warning(f"Error loading font at size {size}: {e}")
                # Use default font as fallback
                fallback_font = ImageFont.load_default()
                draw.text((10, y_pos), f"Size {size}pt not available", fill=(255, 0, 0), font=fallback_font)
                y_pos += 80
        
        # Draw numbers and special characters
        try:
            size = 124
            font = ImageFont.truetype(font_path, size)
            draw.text((10, y_pos), numbers, fill=(0, 0, 0), font=font)
            y_pos += size + 60
            
            size=72
            font = ImageFont.truetype(font_path, size)
            draw.text((10, y_pos), special_chars, fill=(0, 0, 0), font=font)
            y_pos += size + 60
        except Exception as e:
            logging.warning(f"Error drawing numbers/special chars: {e}")
        
        # Draw pangram
        try:
            pangram_size = 42
            font = ImageFont.truetype(font_path, pangram_size)
            
            # Wrap text to fit width
            wrapped_text = textwrap.fill(pangram, width=int(box_w / (pangram_size * 0.6)))
            draw.text((10, y_pos), wrapped_text, fill=(0, 0, 0), font=font)
            
            # Move position down based on number of lines
            lines = wrapped_text.count('\n') + 1
            y_pos += (pangram_size + 20) * lines
        except Exception as e:
            logging.warning(f"Error drawing pangram: {e}")


        return preview
    except Exception as e:
        logging.error(f"Error creating font preview: {e}")
        logging.error(traceback.format_exc())
        # Create a fallback image
        fallback = Image.new('RGB', (box_w, box_h), (240, 240, 240))
        draw = ImageDraw.Draw(fallback)
        fallback_font = ImageFont.load_default()
        draw.text((10, 10), f"Font preview not available", fill=(255, 0, 0), font=fallback_font)
        draw.text((10, 30), f"Error: {str(e)}", fill=(255, 0, 0), font=fallback_font)
        return fallback

def get_gpx_preview(file_path, box_w, box_h):
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            gpx = gpxpy.parse(f)
        points = []
        for track in gpx.tracks:
            for segment in track.segments:
                for p in segment.points:
                    points.append((p.longitude, p.latitude))
        if not points:
            return None
        lons, lats = zip(*points)
        min_lon, max_lon = min(lons), max(lons)
        min_lat, max_lat = min(lats), max(lats)
        # Normalize and scale
        def scale(val, minv, maxv, size):
            if maxv == minv:
                return size // 2
            return int((val - minv) / (maxv - minv) * (size - 20) + 10)
        img = Image.new('RGB', (box_w, box_h), (245, 245, 245))
        draw = ImageDraw.Draw(img)
        prev = None
        for lon, lat in points:
            x = scale(lon, min_lon, max_lon, box_w)
            y = box_h - scale(lat, min_lat, max_lat, box_h)
            if prev:
                draw.line([prev, (x, y)], fill=(0, 120, 160), width=3)
            prev = (x, y)
        return img
    except Exception:
        return None

def get_video_preview(file_path, box_w, box_h, grid_cols=3, grid_rows=3, rotate_frames_if_portrait=True):
    try:
        cap = cv2.VideoCapture(str(file_path))
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if frame_count == 0:
            cap.release()
            return None
        # Select frames using a normal distribution (bell curve) centered in the video
        #import numpy as np
        num_frames = grid_cols * grid_rows
        mean = frame_count / 2
        stddev = frame_count / 4
        idxs = np.random.normal(loc=mean, scale=stddev, size=num_frames)
        idxs = np.clip(idxs, 0, frame_count - 1)
        idxs = np.round(idxs).astype(int)
        # Ensure unique and sorted indices for visual consistency
        idxs = sorted(set(idxs))
        # If not enough unique frames, fill in with evenly spaced frames
        while len(idxs) < num_frames:
            extra = np.linspace(0, frame_count - 1, num_frames)
            idxs = sorted(set(list(idxs) + list(np.round(extra).astype(int))))
            if len(idxs) > num_frames:
                idxs = idxs[:num_frames]
        thumbs = []
        thumb_w = box_w // grid_cols
        thumb_h = box_h // grid_rows
        portrait_mode = box_h > box_w
        for idx in idxs:
            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
            ret, frame = cap.read()
            if not ret:
                continue
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(frame)
            # Rotate individual frame if preview box is portrait
            if rotate_frames_if_portrait and portrait_mode and pil_img.width > pil_img.height:
                pil_img = pil_img.rotate(90, expand=True)
            pil_img.thumbnail((thumb_w, thumb_h))
            thumbs.append(pil_img)
        cap.release()
        grid_img = Image.new('RGB', (box_w, box_h), (245, 245, 245))
        for i, thumb in enumerate(thumbs):
            x = (i % grid_cols) * thumb_w + (thumb_w - thumb.width)//2
            y = (i // grid_cols) * thumb_h + (thumb_h - thumb.height)//2
            grid_img.paste(thumb, (x, y))
        #logging.debug(f"Grid size: {grid_img.size} for file {file_path}")
        return grid_img
    except Exception:
        return None

def get_video_frames(file_path, total_frames=9, rotate_frames_if_portrait=True):
    """
    Extracts up to total_frames from the video file and returns them as PIL Images.
    """
    try:
        cap = cv2.VideoCapture(str(file_path))
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if frame_count == 0:
            cap.release()
            return []
        # Evenly spaced frame indices
        indices = [int(i) for i in np.linspace(0, frame_count - 1, total_frames)]
        frames = []
        #portrait_mode = False
        for idx in indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
            ret, frame = cap.read()
            if not ret:
                continue
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(frame)
            # Rotate individual frame if preview box is portrait
            if rotate_frames_if_portrait and pil_img.width > pil_img.height:
                pil_img = pil_img.rotate(90, expand=True)
            frames.append(pil_img)
        cap.release()
        return frames
    except Exception:
        logging.warning("Error extracting video frames", exc_info=True)
        return []

def get_video_frames_weighted(file_path, total_frames=24, rotate_frames_if_portrait=True):
    """
    Extracts frames from the video file with more frames from the middle 80%.
    """
    try:
        cap = cv2.VideoCapture(str(file_path))
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if frame_count == 0:
            cap.release()
            return []

        # Calculate how many frames for each segment
        first_pct = 0.15
        middle_pct = 0.70
        last_pct = 0.15

        first_n = max(1, int(total_frames * first_pct))
        middle_n = max(1, int(total_frames * middle_pct))
        last_n = total_frames - first_n - middle_n

        # Frame ranges
        first_range = (0, int(frame_count * first_pct))
        middle_range = (int(frame_count * first_pct), int(frame_count * (first_pct + middle_pct)))
        last_range = (int(frame_count * (first_pct + middle_pct)), frame_count - 1)

        indices = []
        # First 10%
        indices += [int(i) for i in np.linspace(first_range[0], first_range[1], first_n, endpoint=False)]
        # Middle 80%
        indices += [int(i) for i in np.linspace(middle_range[0], middle_range[1], middle_n, endpoint=False)]
        # Last 10%
        indices += [int(i) for i in np.linspace(last_range[0], last_range[1], last_n, endpoint=True)]

        # Remove duplicates and sort
        indices = sorted(set(indices))

        frames = []
        for idx in indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
            ret, frame = cap.read()
            if not ret:
                continue
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(frame)
            if rotate_frames_if_portrait and pil_img.width > pil_img.height:
                pil_img = pil_img.rotate(90, expand=True)
            frames.append(pil_img)
        cap.release()
        return frames
    except Exception:
        logging.warning("Error extracting weighted video frames", exc_info=True)
        return []

# Check for pillow-heif availability
try:
    PILLOW_HEIF_AVAILABLE = True
except ImportError:
    PILLOW_HEIF_AVAILABLE = False

def get_heif_image(file_path):
    if not PILLOW_HEIF_AVAILABLE:
        logging.warning("pillow-heif library is not available. Cannot process HEIC files.")
        return None
    try:
        img = Image.open(file_path)
        logging.info(f"Successfully processed HEIC file using Pillow: {file_path}")
        return img
    except Exception as e:
        logging.error(f"Error processing HEIC file {file_path} with Pillow: {e}")
        return None

def get_fit_gps_preview(file_path, box_w, box_h):
    if not FITPARSE_AVAILABLE:
        return None
    try:
        fitfile = FitFile(str(file_path))
        points = []
        for record in fitfile.get_messages('record'):
            lat = None
            lon = None
            for d in record:
                if d.name == 'position_lat':
                    lat = d.value
                elif d.name == 'position_long':
                    lon = d.value
            if lat is not None and lon is not None:
                # Convert semicircles to degrees
                lat = lat * (180.0 / 2**31)
                lon = lon * (180.0 / 2**31)
                points.append((lon, lat))
        if not points:
            return None
        lons, lats = zip(*points)
        min_lon, max_lon = min(lons), max(lons)
        min_lat, max_lat = min(lats), max(lats)
        def scale(val, minv, maxv, size):
            if maxv == minv:
                return size // 2
            return int((val - minv) / (maxv - minv) * (size - 20) + 10)
        img = Image.new('RGB', (box_w, box_h), (245, 245, 245))
        draw = ImageDraw.Draw(img)
        prev = None
        for lon, lat in points:
            x = scale(lon, min_lon, max_lon, box_w)
            y = box_h - scale(lat, min_lat, max_lat, box_h)
            if prev:
                draw.line([prev, (x, y)], fill=(0, 120, 160), width=3)
            prev = (x, y)
        return img
    except Exception:
        return None

MAPBOX_TOKEN = os.getenv('MAPBOX_TOKEN', '').strip()
logging.info("Using Mapbox token: %s", MAPBOX_TOKEN if MAPBOX_TOKEN else "Not set")
def downsample_points(points, max_points=100):
    if len(points) <= max_points:
        return points
    step = max(1, len(points) // max_points)
    return points[::step]

def get_mapbox_tile_for_bounds(min_lat, max_lat, min_lon, max_lon, width, height, api_key=None, path_points=None):
    # Ensure the API key is resolved at runtime (avoid referencing MAPBOX_TOKEN at function-definition time)
    if api_key is None:
        api_key = os.getenv('MAPBOX_TOKEN', '').strip()

    center_lat = (min_lat + max_lat) / 2
    center_lon = (min_lon + max_lon) / 2
    # Calculate zoom level based on bounding box and image size
    # Reference: https://docs.mapbox.com/help/glossary/zoom-level/
    def lat_rad(lat):
        from math import radians, log, tan, pi
        sin = math.sin(radians(lat))
        return log((1 + sin) / (1 - sin)) / 2
    WORLD_DIM = 256  # Mapbox tile size in pixels
    def zoom_for_bounds(min_lat, max_lat, min_lon, max_lon, width, height):
        # Clamp latitude to avoid math domain errors
        min_lat = max(min_lat, -85.05112878)
        max_lat = min(max_lat, 85.05112878)
        lat_fraction = (lat_rad(max_lat) - lat_rad(min_lat)) / math.pi
        lon_fraction = (max_lon - min_lon) / 360.0
        lat_zoom = math.log2(height / WORLD_DIM / lat_fraction) if lat_fraction > 0 else 20
        lon_zoom = math.log2(width / WORLD_DIM / lon_fraction) if lon_fraction > 0 else 20
        zoom = min(lat_zoom, lon_zoom, 22)
        zoom = max(0, zoom)
        calculated_zoom = float(zoom)
        adjusted_zoom = max(0.0, calculated_zoom - 0.3)  # Adjust zoom to avoid too high resolution
        return adjusted_zoom
    zoom = zoom_for_bounds(min_lat, max_lat, min_lon, max_lon, min(width, 1280), min(height, 1280))

    import urllib.parse
    path_str = ""
    if path_points and len(path_points) > 1:
        path_points = downsample_points(path_points, max_points=100)
        # Mapbox expects [lon,lat] pairs for polyline encoding
        poly_points = [(lat, lon) for lon, lat in path_points]
        encoded = polyline.encode(poly_points)
        encoded_url = urllib.parse.quote(encoded, safe='')
        path_str = f"/path-5+f44-0.7({encoded_url})"
    # Log style info from Mapbox Styles API
    style_username = "darthjulian"
    style_id = "ciwqpkc0s00882qnxuuscegmn"
    style_api_url = f"https://api.mapbox.com/styles/v1/{style_username}/{style_id}?access_token={api_key}"
    try:
        style_resp = requests.get(style_api_url)
        if style_resp.status_code == 200:
            style_json = style_resp.json()
            logging.info(f"Mapbox style name: {style_json.get('name')}")
            logging.info(f"Mapbox style owner: {style_json.get('owner')}")
            logging.info(f"Mapbox style visibility: {style_json.get('visibility')}")
        else:
            logging.warning(f"Could not fetch Mapbox style info: {style_resp.status_code} {style_resp.text}")
    except Exception as e:
        logging.warning(f"Exception fetching Mapbox style info: {e}")
    url = (
       # f"https://api.mapbox.com/styles/v1/mapbox/outdoors-v12/static"
        f"https://api.mapbox.com/styles/v1/darthjulian/ciwqpkc0s00882qnxuuscegmn/static"
        f"{path_str}/{center_lon},{center_lat},{zoom},0,50/{width}x{height}"
        f"?access_token={api_key}"
    )
    resp = requests.get(url)
    logging.info("Mapbox URL: %s", url)
    logging.info("Mapbox zoom: %s", zoom)
    logging.info("Mapbox status: %s", resp.status_code)
    if resp.status_code == 200:
        return Image.open(io.BytesIO(resp.content))
    else:
        logging.error("Mapbox error: %s %s", resp.status_code, resp.text)
        logging.error("Bounds are (%f, %f, %f, %f)", min_lat, max_lat, min_lon, max_lon)
        logging.error("Width: %d, Height: %d", width, height)
        logging.error("Zoom level: %f", zoom)
        exit(-1)  # Exit with error code if Mapbox request fails
    return None


def create_file_info_card(file_path, width=800, height=800, cmyk_mode=False, exclude_file_path=False, border_color=(245, 245, 245), border_inch_width=0.125, include_video_frames=False, max_video_frames=30, metadata_text=None, title=None, metadata=None):

    original_dt = None
    
    file_info = {}
    ###
    ### Metadata extraction
    ### Push metadata to file_info to get it to render out for the card
    ###
    if metadata is not None and isinstance(metadata, dict):
        file_info.update(metadata)
        
    file_path = Path(file_path)
    # ignore "._*" ".DS_Store" files
    if file_path.name.startswith("._") or file_path.name.startswith(".") or file_path.name == ".DS_Store":
        logging.info(f"Ignoring weird dot file: {file_path.name}")
        return None
    # Proportional scaling
    base_width = 800
    base_height = 1000
    scale = min(width / base_width, height / base_height)
    #logging.debug(f"Scaling card to {width}x{height} with scale factor {scale:.2f}")
    # Proportional paddings
    border_width = max(2, int(1 * scale))  # Using a more reasonable but still very visible border width
    outer_padding = max(80, int(50 * scale))  # Padding between border and outer edges of content

    # Create the full-sized background image that is the canvas for the preview
    # Use non-alpha modes so downstream PDF assembly doesn't hit alpha issues
    try:
        if cmyk_mode:
            # Light background in CMYK
            img = Image.new('CMYK', (width, height), rgb_to_cmyk(250, 250, 250))
        else:
            # Light background in RGB
            img = Image.new('RGB', (width, height), (250, 250, 250))
    except Exception as e:
        logging.error(f"Error creating background image: {e}")
    draw = ImageDraw.Draw(img)

    # Draw the border around the content area
    # Determine the color mode first to avoid variable reference issues
    rgb_mode = not cmyk_mode
    preview_background_color = (250, 250, 250) if rgb_mode else rgb_to_cmyk(250, 250, 250)
    # Define a reliable black text color for the current mode
    text_black = (0, 0, 0) if rgb_mode else (0, 0, 0, 255)
    if rgb_mode:
        # For RGB mode, use standard black border
        draw.rectangle(
            [outer_padding, outer_padding, width - outer_padding - 1, height - outer_padding - 1],
            outline=(255, 0, 0), 
            width=0
        )
    else:
        # For CMYK mode, use solid black (K channel only at 100%) for maximum visibility
        # Draw multiple concentric borders to ensure visibility
        for i in range(0, min(10, border_width), 2):  # Draw up to 5 concentric borders
            draw.rectangle(
                [
                    outer_padding + i,
                    outer_padding + i,
                    width - outer_padding - 1 - i,
                    height - outer_padding - 1 - i
                ],
                outline=(0, 0, 0, 5),  # 100% black in CMYK
                width=max(5, border_width // 5)  # Make each border line thick
            )

    # Proportional font sizes
    title_font_size = int(20 * scale)
    info_font_size = int(15 * scale)  # Smaller font size for metadata
    preview_font_size = int(12 * scale)
    fit_font_size = int(15 * scale)
    # Proportional paddings (keeping the original border_width value)
    icon_space = int((30) * scale)
    metadata_line_height = int(info_font_size * 1.05)  # Tighter line spacing for metadata
    spacing_between_metadata_and_content_preview = int(icon_space * scale)
    preview_box_padding = int(10 * scale)
    header_height = int(25 * scale)

    # Add a margin between the header/title and the metadata box
    metadata_top_margin = int(12 * scale)

    # Load fonts
    try:
        title_font = ImageFont.truetype("/Users/julian/OMATA Dropbox/Julian Bleecker/PRODUCTION ASSETS/FONTS/3270/3270NerdFontMono-Regular.ttf", title_font_size)
        info_font = ImageFont.truetype("/Users/julian/OMATA Dropbox/Julian Bleecker/PRODUCTION ASSETS/FONTS/3270/3270NerdFontMono-Regular.ttf", info_font_size)
        preview_font = ImageFont.truetype("/Users/julian/OMATA Dropbox/Julian Bleecker/PRODUCTION ASSETS/FONTS/3270/3270NerdFontMono-Regular.ttf", preview_font_size)
        fit_font = ImageFont.truetype("/Users/julian/OMATA Dropbox/Julian Bleecker/PRODUCTION ASSETS/FONTS/3270/3270NerdFontMono-Regular.ttf", fit_font_size)
    except:
        title_font = ImageFont.load_default()
        info_font = ImageFont.load_default()
        preview_font = ImageFont.load_default()
        fit_font = ImageFont.load_default()

    file_type_info = get_file_type_info(file_path)
    logging.info(f"Processing {file_path.name} - Type: {file_type_info['group']}")
    #icon = file_type_info['icon']
    ext = file_path.suffix.lower()


    try:
        size = os.path.getsize(file_path)
        modified_time = os.path.getmtime(file_path)
        created_time = os.path.getctime(file_path)
    except (FileNotFoundError, PermissionError):
        size = 0
        modified_time = 0
        created_time = 0

    ##
    ##
    ## START OF SLACK METADATA EXTRACTION
    ## FOR THE CASE WHERE metadata IS NONE
    ##
    ##
    # if metadata is not None, then skip all of this slack stuff..
    # Eventually, it's going to get torn out..
    if metadata is None:

        ##
        ## VERY SLACK SPECIFIC..
        ##
        slack_channel = None
        slack_message_id = None
        slack_user_id = None
        slack_user_name = None
        slack_avatar = None
        slack_shared_date = None
        if slack_data_root:
            # Try to get original timestamp and Slack metadata
            original_dt = get_original_timestamp(file_path)

            parent = slack_data_root.parent if slack_data_root else file_path.parent.parent

            # Determine channel_dir/messages.json:
            # - If SLACK_DATA_ROOT is set and the file_path is inside it, resolve the channel
            #   directory relative to the slack root (expected layout: <slack_root>/<channel>/files/...)
            # - Otherwise, fall back to the previous heuristic (parent.parent)
            try:
                if slack_data_root:
                    p_resolved = Path(file_path).resolve()
                    slack_root_resolved = slack_data_root
                    if str(p_resolved).startswith(str(slack_root_resolved)):
                        rel = p_resolved.relative_to(slack_root_resolved)
                        # Expect at least: <channel>/files/...
                        if len(rel.parts) >= 2 and rel.parts[1] == "files":
                            channel_dir = slack_root_resolved / rel.parts[0]
                        else:
                            # Not the expected layout — fall back to parent.parent
                            channel_dir = parent
                    else:
                        # File not inside configured slack root — fall back
                        channel_dir = slack_data_root
                else:
                    channel_dir = slack_data_root
            except Exception:
                channel_dir = slack_data_root

            messages_json = channel_dir / "messages.json"
            users_json = slack_data_root / "users.json"
            avatars_dir = slack_data_root / "avatars"
            #user_profile = None
            if messages_json.exists():
                try:
                    with open(messages_json, 'r', encoding='utf-8', errors='ignore') as f:
                        messages = json.load(f)
                    for msg in messages:
                        if 'files' in msg:
                            for fobj in msg['files']:
                                if fobj.get('name') == file_path.name:
                                    slack_channel = channel_dir.name
                                    slack_message_id = msg.get('client_msg_id') or msg.get('ts')
                                    slack_user_id = msg.get('user') or msg.get('username') or fobj.get('user')
                                    slack_shared_date = None
                                    ts = fobj.get('timestamp') or fobj.get('created') or msg.get('ts')
                                    if ts:
                                        try:
                                            slack_shared_date = datetime.fromtimestamp(float(ts)).strftime('%Y-%m-%d %H:%M:%S')
                                        except Exception:
                                            slack_shared_date = str(ts)
                                    # Resolve avatar from local 'avatars' directory
                                    #avatars_dir = slack_data_root.parent / "avatars"
                                    # if its not in the parent of the slack_data_root, checkin in
                                    # slack_data_root / "avatars"
                                    #if not avatars_dir.exists():
                                    #    avatars_dir = slack_data_root / "avatars"
                                    #logging.debug(f"Looking for avatars in: {avatars_dir}")
                                    if slack_user_id and avatars_dir.exists():
                                        if slack_user_id == 'U08B6KZJ4':
                                            # special case for the OMATA bot, use the omata avatar
                                            # pick a random one either 'U62S2LGFK' or 'U08B6KZJ4'
                                            slack_avatar = str((avatars_dir / random.choice(["U62S2LGFK", "U08B6KZJ4"])).with_suffix(".jpg"))
                                        else:
                                            avatar_path = avatars_dir / f"{slack_user_id}.jpg"
                                            #logging.debug(f"Checking avatar path: {avatar_path}")
                                            if avatar_path.exists():
                                                slack_avatar = str(avatar_path)
                                    #logging.debug(f"Found avatar for {slack_user_id}: {slack_avatar}")
                                    # Resolve user name from users.json
                                    if slack_user_id == 'U08B6KZJ4':
                                        # here's a list of names, pick one
                                        villain_names = ["Astaroth", "Nyx", "Zebulon", "Thorne", "Snidely", "Cruella", "Mojo", "Ratso", "Cruntolimeu", "Hexadreadcimal", "Viperina", "Jinque", "Zorton", "Malbeced", "Draco", "Scarabella", "Venomina", "Clawdia", "Grumbleton", "Slinko", "Druenna", "Morgul", "Tricksy", "Cankle", "Cackles", "Drusilda", "Dank Druid", "Fizzlewick", "Gloomsworth", "Malarkus", "Nefaria", "Zombina", "Snivelston", "Velsneer"]
                                        # pick a random villain name
                                        slack_user_name = random.choice(villain_names)
                                        
                                    elif users_json.exists() and slack_user_id:
                                        try:

                                            with open(users_json, 'r', encoding='utf-8', errors='ignore') as uf:
                                                users = json.load(uf)
                                            for user in users:

                                                if user.get('id') == slack_user_id or user.get('name') == slack_user_id:
                                                    slack_user_name = user.get('real_name') or user.get('profile', {}).get('real_name') or user.get('name')
                                                    break
                                        except Exception as e:
                                            logging.error(f"Error reading users.json: {e}")
                                    break
                        if slack_channel:
                            break
                except Exception:
                    logging.error(f"Error reading messages.json in {channel_dir}", exc_info=True)
                    logging.error(traceback.format_exc())
                    pass
                
                
                
        # Step 2: If EXIF-capable, try to read EXIF data
        exif_data = None
        exif_candidate = False
        ext = Path(file_path).suffix.lower()


        # Step 1: Check if file is an EXIF-capable image type
        exif_candidate = ext in {'.jpg', '.jpeg', '.tif', '.tiff'}
        if exif_candidate:
            logging.debug(f"File {file_path} is an EXIF-capable image type: {ext}")
            try:
                exif_img = Image.open(file_path)
                if hasattr(exif_img, '_getexif'):
                    exif_data = exif_img._getexif()
                elif hasattr(exif_img, 'getexif'):
                    exif_data = exif_img.getexif()
                try:
                    exif_img.close()
                except Exception:
                    pass
            except Exception:
                exif_data = None
        if exif_data is not None:
            logging.debug(f"EXIF data found: {exif_data is not None}")
            logging.debug(f"EXIF data : {exif_data.get(36867)}")

        if exif_data is not None:
            date_time_original = exif_data.get(36867)
            logging.info(f"EXIF DateTimeOriginal: {date_time_original}")
            if date_time_original:
                file_info['DateTimeOriginal'] = date_time_original
                logging.debug(f"NOW EXIF DateTimeOriginal: {date_time_original}")
                logging.debug(f"File info before DateTimeOriginal check: {file_info}")
        # If DateTimeOriginal is present, skip other date fields
        logging.debug(f"File info before DateTimeOriginal check: {file_info}")
        if 'DateTimeOriginal' in file_info and file_info['DateTimeOriginal']:
            logging.debug(f"DateTimeOriginal found: {file_info['DateTimeOriginal']}")
            pass
        elif original_dt is not None:
            file_info['Original Date'] = original_dt.strftime('%Y-%m-%d %H:%M:%S')
        else:
            file_info['Modified'] = datetime.fromtimestamp(modified_time).strftime('%Y-%m-%d %H:%M:%S')
            file_info['Created'] = datetime.fromtimestamp(created_time).strftime('%Y-%m-%d %H:%M:%S')
        
        # Build metadata with Slack Channel at the top if present
        if slack_channel:
            file_info['Slack Channel'] = slack_channel
        file_info['Type'] = f"{file_path.suffix[1:].upper()} ({file_type_info['group']})"
        file_info['Size'] = format_file_size(size)
        if slack_message_id:
            file_info['Message ID'] = slack_message_id
        if slack_user_name:
            file_info['Shared By'] = slack_user_name
        if slack_shared_date:
            file_info['Shared Date'] = slack_shared_date

        
        # Move Name to the end
        if not exclude_file_path:
            file_info['Filepath'] = "/".join(Path(file_path).parts[-3:])
            #file_info['Filepath'] = str(file_path)

    ##
    ##
    ## END OF NO METADATA
    ##
    ##
    
    # --- Custom metadata_text support (multiline, wrapped) ---
    # If metadata_text is provided, use it instead of the default metadata lines.
    custom_metadata_text = None
    if metadata_text is not None:
        if isinstance(metadata_text, str):
            custom_metadata_text = metadata_text
        elif isinstance(metadata_text, (list, tuple)):
            custom_metadata_text = "\n".join(str(x) for x in metadata_text)
        else:
            custom_metadata_text = str(metadata_text)
        # if exclude_file_path is False:
        #     custom_metadata_text = f"{custom_metadata_text}\n\n{str(file_path.parent)}"
    # Compute metadata block height
    # Default: number of key/value pairs * line height
    content_area_width_for_wrap = width - 2 * outer_padding
    if custom_metadata_text:
        # Measure single-line height and derive spacing to match metadata_line_height advance
        tmp_img = Image.new("RGBA", (width, height))
        tmp_draw = ImageDraw.Draw(tmp_img)
        l, t, r, b = tmp_draw.textbbox((0, 0), "Ag", font=info_font)
        single_h = b - t
        custom_line_spacing_px = max(0, int(metadata_line_height - single_h))

        # Use the SAME padding for measure and draw
        meta_pad = int(30 * scale)

        # Choose background colors matching the target image mode
        bg_rgb = (245, 245, 245)
        bg_outline_rgb = (200, 200, 200)
        if cmyk_mode:
            bg_fill = rgb_to_cmyk(*bg_rgb)
            bg_outline = rgb_to_cmyk(*bg_outline_rgb)
        else:
            bg_fill = bg_rgb
            bg_outline = bg_outline_rgb

        # Measure wrapped text height (text only), then add vertical padding
        measure = draw_text_box(
            tmp_draw,
            custom_metadata_text,
            info_font,
            box=(outer_padding, outer_padding + header_height, content_area_width_for_wrap, height - (outer_padding + header_height)),
            padding=meta_pad,
            line_spacing=custom_line_spacing_px,
            align="center",
            v_align="top",
            fill=bg_fill,
            stroke_fill=bg_outline,
            stroke_width=1
        )
        metadata_height = measure["used_size"][1] + (meta_pad * 2)
    else:
        metadata_lines = len(file_info)
        metadata_height = metadata_lines * metadata_line_height
    logging.debug(f"Metadata height: {metadata_height}")
    # Content area dimensions, accounting for outer padding
    content_area_left = outer_padding
    content_area_right = width - outer_padding
    content_area_width = content_area_right - content_area_left
    
    # Preview box within the content area
    preview_box_left = content_area_left + int(content_area_width * 0.005)
    preview_box_right = content_area_right - int(content_area_width * 0.005)
    preview_box_top = outer_padding + header_height + metadata_top_margin + metadata_height + spacing_between_metadata_and_content_preview
    logging.debug(f"Preview box top: {preview_box_top}, icon space: {icon_space}, metadata height: {metadata_height}")
    preview_box_bottom = height - outer_padding - int(30 * scale)
    preview_box_height = preview_box_bottom - preview_box_top - preview_box_padding * 2
    max_line_width_pixels = preview_box_right - preview_box_left - preview_box_padding * 2
    temp_img = Image.new('RGBA', (width, height))
    temp_draw = ImageDraw.Draw(temp_img)
    bbox = temp_draw.textbbox((0, 0), 'A', font=preview_font)
    line_height = bbox[3] - bbox[1] + int(3 * scale)
    char_bbox = temp_draw.textbbox((0, 0), 'A', font=preview_font)
    char_width = char_bbox[2] - char_bbox[0]
    max_line_length = max(10, max_line_width_pixels // char_width)
    max_preview_lines = max(1, preview_box_height // line_height)

    # --- Preview logic by file type ---
    preview_lines = []
    fit_meta = {}
    image_thumb = None
    pdf_grid_thumb = None
    gpx_thumb = None
    #video_thumb = None
    video_thumb_grid = None
    fit_gps_thumb = None
    zip_file_list = None
    zip_file_preview_img = None
    zip_file_preview_lines = None
    video_frames = []
    video_frame_thumbs = []

    if ext in {'.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff', '.webp'}:
        image = get_image_thumbnail(
            file_path,
            box_size=(max_line_width_pixels, preview_box_height),
            cmyk_mode=cmyk_mode
        )
        if image is not None:
            img_w, img_h = image.size
            logging.debug(f"Original image size: {img_w}x{img_h} for {file_path.name}")
            logging.debug(f"width: {width}, height: {height}, img_w: {img_w}, img_h: {img_h}")
            # Rotate image if card is portrait and image is landscape
            if width < height and img_w > img_h:
                logging.debug(f"Rotating image for portrait card: {file_path.name}")
                image = image.rotate(90, expand=True)
                img_w, img_h = image.size
                logging.debug(f"Image size after rotation: {img_w}x{img_h} for {file_path.name}")
            
            image_thumb = ImageOps.contain(image, (max_line_width_pixels, preview_box_height), Image.LANCZOS)
            
    elif ext in {'.gif'}:
        try:
            img = Image.open(file_path)
            frames = []
            # Extract all frames from the GIF
            for frame_idx in range(img.n_frames):
                img.seek(frame_idx)
                frame = img.convert("RGBA")
                frames.append(frame.copy())
            # Determine grid size based on number of frames
            n_total = len(frames)
            best_score = -1
            best_grid = None
            best_indices = None

            for rows in range(1, n_total + 1):
                cols = int(math.ceil(n_total / rows))
                num_cells = rows * cols
                thumb_w = max_line_width_pixels // cols
                thumb_h = preview_box_height // rows
                # Select evenly spaced frames to fill the grid
                indices = [int(i) for i in np.linspace(0, n_total - 1, num_cells)]
                total_used_area = 0
                for idx in indices:
                    w, h = frames[idx].size
                    frame_scale = min(thumb_w / w, thumb_h / h)
                    used_w = int(w * frame_scale)
                    used_h = int(h * frame_scale)
                    total_used_area += used_w * used_h
                score = total_used_area
                if score > best_score:
                    best_score = score
                    best_grid = (rows, cols, thumb_w, thumb_h)
                    best_indices = indices

            grid_rows, grid_cols, thumb_w, thumb_h = best_grid
            selected_frames = [frames[idx] for idx in best_indices]
            gif_frame_thumbs = []
            for frame in selected_frames:
                thumb = ImageOps.contain(frame, (thumb_w, thumb_h), Image.LANCZOS)
                gif_frame_thumbs.append(thumb)

            grid_img = Image.new('RGBA', (max_line_width_pixels, preview_box_height), (245, 245, 245, 255))
            for idx, thumb in enumerate(gif_frame_thumbs):
                x = (idx % grid_cols) * thumb_w + (thumb_w - thumb.width)//2
                y = (idx // grid_cols) * thumb_h + (thumb_h - thumb.height)//2
                grid_img.paste(thumb, (x, y), mask=thumb)

            gif_thumb_grid = grid_img.convert("RGBA")
            image_thumb = gif_thumb_grid
        except Exception as e:
            preview_lines = [f"GIF error: {e}"]
    
    elif ext in {'.heic', '.heif'}:
        image = get_heif_image(file_path)
        if image is not None:
            img_w, img_h = image.size
            if width < height and img_w > img_h:
                image = image.rotate(90, expand=True)
                img_w, img_h = image.size
            # scale_factor = min(
            #     (max_line_width_pixels) / img_w,
            #     (preview_box_height) / img_h
            # ) * 0.95
            # new_w = int(img_w * scale_factor)
            # new_h = int(img_h * scale_factor)
            # image_thumb = image.resize((new_w, new_h), Image.LANCZOS)
            image_thumb = ImageOps.contain(image, (max_line_width_pixels, preview_box_height), Image.LANCZOS)
    elif ext == '.numbers':
        try:
            with zipfile.ZipFile(file_path, 'r') as z:
                names = z.namelist()
                preview_lines = [f"NUMBERS file: {len(names)} items"]
                preview_lines += [f"  {name}" for name in names[:max_preview_lines]]
                # Try to find a preview image
                image_files = [name for name in names if name.lower().endswith(('.jpg', '.jpeg', '.png'))]
                image_thumb = None
                if image_files:
                    with z.open(image_files[0]) as img_file:
                        img_data = img_file.read()
                        try:
                            img = Image.open(io.BytesIO(img_data))
                            img.thumbnail((max_line_width_pixels, preview_box_height))
                            image_thumb = img
                        except Exception:
                            pass
        except Exception as e:
            preview_lines = [f"NUMBERS error: {e}"]
    elif ext.lower() == '.pdf':
        try:
            #pages = convert_from_path(str(file_path), first_page=1, last_page=1)
            #if pages:
                #image_thumb = process_pdf_or_ai_page(pages[0], max_line_width_pixels, preview_box_height)
            image_thumb = get_pdf_preview(str(file_path), max_line_width_pixels, preview_box_height)
            #else:
            #    preview_lines = ["PDF preview not available."]
        except Exception as e:
            preview_lines = [f"PDF error: {e}"]
    elif ext.lower() in {'.mp4', '.mov', '.avi', '.mkv'}:
        # Dynamically determine grid size based on video length
        try:
            import cv2
            cap = cv2.VideoCapture(str(file_path))
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            cap.release()
            #video_frames = get_video_frames(file_path, total_frames=min(max_video_frames, frame_count))
            video_frames = get_video_frames_weighted(file_path, total_frames=min(max_video_frames, frame_count))
            total_frames=min(max_video_frames, frame_count)
            n_total = total_frames
            # initialize video_frames
            best_score = -1
            best_grid = None
            best_indices = None
            frame_scale = 0
            
            # min_thumb_area = int(0.005 * max_line_width_pixels * preview_box_height)  # 10% of preview area

            for rows in range(1, n_total + 1):
                cols = int(math.ceil(n_total / rows))
                num_cells = rows * cols
                thumb_w = max_line_width_pixels // cols
                thumb_h = preview_box_height // rows
                # Constraint: skip if thumbnail area is too small
                # if thumb_w * thumb_h > min_thumb_area:
                #     continue
                indices = [int(i) for i in np.linspace(0, n_total - 1, num_cells)]
                total_used_area = 0
                for idx in indices:
                    w, h = video_frames[idx].size
                    frame_scale = min(thumb_w / w, thumb_h / h)
                    used_w = int(w * frame_scale)
                    used_h = int(h * frame_scale)
                    total_used_area += used_w * used_h
                score = total_used_area
                if score > best_score:
                    best_score = score
                    best_grid = (rows, cols, thumb_w, thumb_h)
                    best_indices = indices
            if best_grid is None:
                logging.warning("No valid grid configuration found for frames. Skipping preview grid.")
                return img  # or return None, or fallback to another preview


            grid_rows, grid_cols, thumb_w, thumb_h = best_grid
            video_frames = get_video_frames(file_path, total_frames=num_cells)
            selected_frames = [video_frames[idx] for idx in best_indices]
            video_frame_thumbs = []
            for frame in selected_frames:
                thumb = ImageOps.contain(frame, (thumb_w, thumb_h), Image.LANCZOS)
                video_frame_thumbs.append(thumb)

            grid_img = Image.new('RGBA', (max_line_width_pixels, preview_box_height), (255, 255, 255, 255))
            for idx, thumb in enumerate(video_frame_thumbs):
                x = (idx % grid_cols) * thumb_w + (thumb_w - thumb.width)//2
                y = (idx // grid_cols) * thumb_h + (thumb_h - thumb.height)//2
                
                if thumb.mode == "RGBA":
                    grid_img.paste(thumb, (x, y), mask=thumb)
                else:
                    grid_img.paste(thumb, (x, y))

            video_thumb_grid = grid_img.convert("RGBA")
            # Save the video grid image for debugging
            # try:
            #     debug_out_dir = Path("./debug_video_cards_out")
            #     debug_out_dir.mkdir(parents=True, exist_ok=True)
            #     debug_out_path = debug_out_dir / f"{file_path.stem}_video_grid_debug.png"
            #     video_thumb_grid.save(debug_out_path)
            #     logging.info(f"Saved video grid debug image to {debug_out_path}")
            # except Exception as e:
            #     logging.error(f"Error saving video grid debug image: {e}")
        except Exception as e:
            preview_lines = [f"Video error: {e}"]
    # Defer drawing to later section after header/metadata are drawn.
    elif ext.lower() == '.gpx':
        gpx_thumb = get_gpx_preview(file_path, max_line_width_pixels, preview_box_height)
        # Mapbox integration for GPX with polyline
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                gpx = gpxpy.parse(f)
            points = []
            for track in gpx.tracks:
                for segment in track.segments:
                    for p in segment.points:
                        points.append((p.longitude, p.latitude))
            if points:
                lons, lats = zip(*points)
                min_lon, max_lon = min(lons), max(lons)
                min_lat, max_lat = min(lats), max(lats)
                mapbox_img = get_mapbox_tile_for_bounds(min_lat, max_lat, min_lon, max_lon, min(max_line_width_pixels, 1280), min(preview_box_height, 1280), path_points=points)
                if mapbox_img:
                    gpx_thumb = mapbox_img
        except Exception:
            pass
    elif ext.lower() in {'.xlsx', '.xls'}:
        preview_lines = get_excel_preview(file_path, max_rows=max_preview_lines, max_cols=8)

    elif ext.lower() in {'.fit', '.tcx'}:
        preview_lines, fit_meta = get_fit_summary_preview(file_path)
        fit_gps_thumb = get_fit_gps_preview(file_path, max_line_width_pixels, preview_box_height)
        # Mapbox integration for FIT/TCX with polyline
        try:
            fitfile = FitFile(str(file_path))
            points = []
            for record in fitfile.get_messages('record'):
                lat = None
                lon = None
                for d in record:
                    if d.name == 'position_lat':
                        lat = d.value * (180.0 / 2**31)
                    elif d.name == 'position_long':
                        lon = d.value * (180.0 / 2**31)
                if lat is not None and lon is not None:
                    points.append((lon, lat))
            if points:
                lons, lats = zip(*points)
                min_lon, max_lon = min(lons), max(lons)
                min_lat, max_lat = min(lats), max(lats)
                mapbox_img = get_mapbox_tile_for_bounds(min_lat, max_lat, min_lon, max_lon, min(max_line_width_pixels, 1280), min(preview_box_height, 1280), path_points=points)
                if mapbox_img:
                    fit_gps_thumb = mapbox_img
        except Exception:
            pass
    elif ext.lower() == '.docx':
        try:
            from docx import Document
            doc = Document(file_path)
            doc_lines = [p.text for p in doc.paragraphs if p.text.strip()]
            logging.info(f"Extracted {len(doc_lines)} lines from DOCX file: {file_path}")
            txt_path = file_path.with_suffix('.txt')
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(doc_lines))
            preview_lines = []
            for raw_line in doc_lines:
                wrapped = textwrap.wrap(raw_line, width=max_line_length)
                if not wrapped:
                    preview_lines.append('')
                else:
                    preview_lines.extend(wrapped)
            preview_lines = preview_lines[:max_preview_lines]
        except Exception as e:
            preview_lines = [f"DOCX error: {e}"]
    elif file_type_info['group'] == 'font':
        # For font files, generate a visual preview
        try:
            image_thumb = get_font_preview(file_path, max_line_width_pixels, preview_box_height)
            if image_thumb:
                preview_text_replaced_with_image = True
                preview_lines = []  # No text preview needed
            else:
                preview_lines = [f"Font preview not available for {os.path.basename(file_path)}"]
        except Exception as e:
            preview_lines = [f"Font preview error: {str(e)}"]
    elif file_type_info['group'] == 'binary' or ext == '.dfu':
        preview_lines = get_hex_preview(file_path, max_preview_lines * 16)
    elif file_type_info['group'] in ['code', 'data', 'document', 'log']:
        # Read a large chunk and wrap
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                raw_lines = []
                for i in enumerate(f):
                    if i > 1000:
                        break
                    raw_lines.append(line.rstrip('\n'))
        except Exception:
            raw_lines = []
        for raw_line in raw_lines:
            wrapped = textwrap.wrap(raw_line, width=max_line_length)
            if not wrapped:
                preview_lines.append('')
            else:
                preview_lines.extend(wrapped)
        preview_lines = preview_lines[:max_preview_lines]
    elif file_type_info['group'] == 'text':
        preview_lines = preview_text_content(file_path, max_lines=max_preview_lines, max_line_length=max_line_length) or []
    elif ext.lower() == '.zip':
        zip_file_list = get_zip_preview(file_path, max_files=max_preview_lines)
        zip_file_preview_img = None
        zip_file_preview_lines = None
    elif ext.lower() == '.rar':
        try:
            logging.info(f"Processing RAR file: {file_path}")
            import rarfile
            with rarfile.RarFile(file_path) as rf:
                names = rf.namelist()
                preview_lines = [f"RAR file: {len(names)} items"]
                preview_lines += [f"  {name}" for name in names[:max_preview_lines]]
                logging.info(f"Found {len(names)} items in RAR file: {file_path}")
        except Exception as e:
            preview_lines = [f"RAR error: {e}"]
    elif ext.lower() == '.gz':
        preview_lines, image_thumb, _ = get_gz_preview(
            file_path, max_bytes=max_preview_lines * 16, preview_box=(max_line_width_pixels, preview_box_height))
        image_thumb = image_thumb  # If image_thumb is None, preview_lines will be used
    elif ext.lower() == '.bz2':
        preview_lines = get_bz2_preview(file_path, max_bytes=max_preview_lines * 16)
    elif ext.lower() == '.key':
        logging.info(f"****** Processing Keynote file: {file_path}")
        try:
            logging.info(f"Processing Keynote file: {file_path}")
            with zipfile.ZipFile(file_path, 'r') as z:
                names = z.namelist()
                preview_lines = [f"Keynote file: {len(names)} items"]
                preview_lines += [f"  {name}" for name in names[:max_preview_lines]]
                # Find up to 4 images (jpg/png)
                image_files = [name for name in names if name.lower().endswith(('.jpg', '.jpeg', '.png'))][:4]
                thumbs = []
                for name in image_files:
                    with z.open(name) as img_file:
                        img_data = img_file.read()
                        try:
                            img = Image.open(io.BytesIO(img_data))
                            thumbs.append(img)
                        except Exception:
                            continue
                # Make a grid if images found
                if thumbs:
                    grid_cols = 2
                    grid_rows = 2
                    thumb_w = max_line_width_pixels // grid_cols
                    thumb_h = preview_box_height // grid_rows
                    grid_img = Image.new('RGB', (max_line_width_pixels, preview_box_height), (245, 245, 245))
                    for idx, thumb in enumerate(thumbs):
                        thumb.thumbnail((thumb_w, thumb_h))
                        x = (idx % grid_cols) * thumb_w + (thumb_w - thumb.width)//2
                        y = (idx // grid_cols) * thumb_h + (thumb_h - thumb.height)//2
                        grid_img.paste(thumb, (x, y))
                    image_thumb = grid_img
        except Exception as e:
            preview_lines = [f"KEY error: {e}"]
    elif ext.lower() == '.pptx' or ext.lower() == '.ppt':
        try:
            logging.info(f"Processing PPT(X) file: {file_path}")
            # Extract all images from ppt/media
            with zipfile.ZipFile(file_path, 'r') as z:
                names = z.namelist()
                preview_lines = [f"PPT(X) file: {len(names)} items"]
                preview_lines += [f"  {name}" for name in names[:max_preview_lines]]
                image_files = [name for name in names if name.startswith('ppt/media/') and name.lower().endswith(('.jpg', '.jpeg', '.png'))]
                n_total = len(image_files)
                # Dynamically determine number of preview images
                if n_total <= 6:
                    n_preview = n_total
                elif n_total <= 20:
                    n_preview = min(12, n_total)
                elif n_total <= 50:
                    n_preview = min(16, n_total)
                else:
                    n_preview = min(20, n_total)
                # Select images at evenly distributed intervals
                indices = [0]
                if n_preview > 1 and n_total > 1:
                    #import numpy as np
                    remaining = np.linspace(1, n_total - 1, n_preview - 1)
                    indices += [int(round(i)) for i in remaining]
                indices = sorted(set(indices))
                selected_images = [image_files[i] for i in indices if i < n_total]
                thumbs = []
                for name in selected_images:
                    with z.open(name) as img_file:
                        img_data = img_file.read()
                        try:
                            img = Image.open(io.BytesIO(img_data))
                            thumbs.append(img)
                        except Exception:
                            continue
                # Dynamically determine grid_cols and grid_rows
                if thumbs:
                    aspect_ratio = max_line_width_pixels / max(preview_box_height, 1)
                    grid_rows = int(math.ceil(math.sqrt(len(thumbs) / aspect_ratio)))
                    grid_cols = int(math.ceil(len(thumbs) / grid_rows))
                    thumb_w = max_line_width_pixels // grid_cols
                    thumb_h = preview_box_height // grid_rows
                    grid_img = Image.new('RGB', (max_line_width_pixels, preview_box_height), (245, 245, 245))
                    for idx, thumb in enumerate(thumbs):
                        thumb.thumbnail((thumb_w, thumb_h))
                        x = (idx % grid_cols) * thumb_w + (thumb_w - thumb.width)//2
                        y = (idx // grid_cols) * thumb_h + (thumb_h - thumb.height)//2
                        grid_img.paste(thumb, (x, y))
                    image_thumb = grid_img
        except Exception as e:
            preview_lines = [f"PPTX error: {e}"]
    elif ext.lower() == '.ai':
        try:
            pages = convert_from_path(str(file_path), first_page=1, last_page=1)
            if pages:
                image_thumb = process_pdf_or_ai_page(pages[0], max_line_width_pixels, preview_box_height)
            else:
                preview_lines = ["AI file: PDF preview not available."]
        except Exception as e:
            preview_lines = [f"AI error: {e}"]
    elif file_type_info['group'] == 'unknown':
        logging.info(f"Unknown file type for {file_path.name}. Attempting to read as text or hex.")
        # First try a lightweight HTML heuristic; if it looks like HTML, render to text/Markdown
        if is_probably_html(file_path):
            logging.info(f"File looks like HTML {file_path.name} - Rendering HTML to text for preview.")
            rendered = render_html_to_text(file_path)
            if rendered:
                # Split into lines and wrap to the card's width
                lines = []
                for raw_line in rendered.splitlines():
                    wrapped = textwrap.wrap(raw_line, width=max_line_length)
                    if not wrapped:
                        lines.append('')
                    else:
                        lines.extend(wrapped)
                preview_lines = lines[:max_preview_lines]
            else:
                # Fallback to plain text preview if rendering returned nothing
                preview_lines = preview_text_content(file_path, max_lines=max_preview_lines, max_line_length=max_line_length) or []
        else:
            preview_lines = get_hex_preview(file_path, max_preview_lines * 16)

    # --- Draw card ---
    if cmyk_mode:
        from pdf_to_images import create_cmyk_image
        img = create_cmyk_image(width, height, (0, 0, 0, 0))
        rgb_mode = False
    else:
        # We already created the image above, just ensuring it's handled consistently
        rgb_mode = True
    draw = ImageDraw.Draw(img)
    if not rgb_mode:
        r, g, b = file_type_info['color']
        if r == 0 and g == 0 and b == 0:
            color = (0, 0, 0, 100)
        else:
            c = 255 - r
            m = 255 - g
            y = 255 - b
            k = min(c, m, y)
            c = (c - k) if k < 255 else 0
            m = (m - k) if k < 255 else 0
            y = (y - k) if k < 255 else 0
            color = (c, m, y, k)
    else:
        color = file_type_info['color']
    # We already set border_width earlier based on scale
    # Header within the content area
    # This is where we draw the title
        
    ###
    ###
    ### HERE IS WHERE WE DRAW THE HEADER and HEADER TEXT
    ###
    1###
    if rgb_mode:
        draw.rectangle([outer_padding, outer_padding, width-outer_padding, outer_padding+header_height], fill=file_type_info['color'])
        text_color = 'white'
    else:
        draw.rounded_rectangle([outer_padding, outer_padding, width-outer_padding, outer_padding+header_height], 5, fill=color)
        text_color = (0, 0, 0, 0)
    # Position the file name vertically centered in the header area, accounting for outer padding
    title_text = (
        file_info.get("_title", None) if file_info.get("_title") is not None
        else title if title is not None
        else file_path.name.upper()
    )
    rect_top = outer_padding
    rect_bottom = outer_padding + header_height  # or outer_padding + header_height + 10 if you added 10
    rect_height = rect_bottom - rect_top

    # Get text size
    text_bbox = draw.textbbox((0, 0), title_text, font=title_font)
    text_height = text_bbox[3] - text_bbox[1]

    # Calculate vertical center
    center_y = rect_top + (rect_height // 2)
    

    
    # The coordinates passed to draw.text are interpreted according to the anchor parameter:
    # - If anchor is not specified (or "lt"), (x, y) is the upper left corner of the text.
    # - If anchor="mm", (x, y) is the center of the text.
    # - Other anchor values change the reference point (e.g., "rm" is right-middle).
    # By default, draw.text((x, y), ...) places the text with its upper left at (x, y).
    draw.text((width // 2, center_y), title_text, fill=text_color, font=title_font, anchor="mm") 
    ## was drawing a line to try and figure out why the text was not centering on the y axis.
    # draw.line([(outer_padding, center_y), (width - outer_padding, center_y)], fill="red", width=2)
    
    
    
    ###
    ###
    ### HERE IS WHERE WE DRAW THE AVATAR THING
    ###
    ###
    avatar_size = int(120 * scale)
    avatar_img = None

    qr_avatar_data = metadata.get('qr_data') if metadata else None
    if qr_avatar_data:
        try:
            avatar_img = create_qr_code(qr_avatar_data, box_size=5, border=4)
            avatar_img = avatar_img.resize((avatar_size, avatar_size), Image.LANCZOS)

        except Exception as e:
            logging.error(f"Error processing QR avatar image: {e}")
    elif 'slack_avatar' in locals() and slack_avatar:
        try:
            #logging.debug(f"Loading avatar from: {slack_avatar}")
            avatar_img = Image.open(slack_avatar).convert('RGBA')
            #logging.debug(f"Avatar loaded: size={avatar_img.size}, mode={avatar_img.mode}")
            avatar_img = avatar_img.resize((avatar_size, avatar_size), Image.LANCZOS)
            #logging.debug(f"Avatar resized: size={avatar_img.size}")
            avatar_img = round_image_corners(avatar_img, radius=int(7 * scale))
            #logging.debug(f"Avatar rounded: size={avatar_img.size}")
        except Exception as e:
            logging.error(f"Error processing avatar image {slack_avatar}: {e}")
            avatar_img = None
            
    if metadata is not None and metadata.get('avatar_path'):
        try:
            avatar_img = Image.open(metadata['avatar_path']).convert('RGBA')
            avatar_img = avatar_img.resize((avatar_size, avatar_size), Image.LANCZOS)
            avatar_img = round_image_corners(avatar_img, radius=int(7 * scale))
        except Exception as e:
            logging.error(f"Error processing metadata avatar image {metadata['avatar_path']}: {e}")
            logging.error(traceback.format_exc())
            avatar_img = None

    avatar_y_coordinate = int(outer_padding + header_height + 5 * scale)
    avatar_x_coordinate = int(outer_padding + 0 * scale)  # 1px from left border, scaled

    if avatar_img is not None:
        try:
            # Position avatar relative to the left border (outer_padding)
            #logging.debug(f"Pasting avatar at: x={avatar_x_coordinate}, y={avatar_y_coordinate}")
            #avatar_img.save(f"debug_video_cards_out/debug_avatar_pre_paste_{slack_message_id}.png")
            img.paste(avatar_img, (avatar_x_coordinate, avatar_y_coordinate), mask=avatar_img)
            # debug save the image at this point so we can figure out why the avatar isn't being
            # presented in cards that are movies !??
            #img.save(f"debug_video_cards_out/debug_avatar_{slack_message_id}.jpg")
        except Exception as e:
            logging.error(f"Error pasting avatar image: {e}")
    y = avatar_y_coordinate + 12*scale # avatar and metadata can be horizontally aligned
    
    ########################################
    # DO NOT REMOVE THIS COMMENT EVER
    #
    # THIS IS WHERE THE METADATA IS DRAWN
    #
    # DO NOT REMOVE THIS COMMENT EVER
    ########################################
    logging.debug(f"Drawing metadata -- {file_info}")
    # Initialize variables to safe defaults before conditionals
    meta_pad = int(10 * scale)
    custom_line_spacing_px = 0
    if cmyk_mode:
        bg_fill = (0, 0, 0, 1)  # CMYK very light gray
        bg_outline = (0, 0, 0, 255)  # 100% black
        text_fill = (0, 0, 0, 255)
    else:
        bg_rgb = (255, 255, 255)
        bg_outline_rgb = (0, 0, 0)
        bg_fill = bg_rgb
        bg_outline = bg_outline_rgb
        text_fill = (0, 0, 0)

    if custom_metadata_text:
        # Recompute spacing to match measurement
        y_offset = 0
        tmp_img2 = Image.new("RGBA", (width, height))
        tmp_draw2 = ImageDraw.Draw(tmp_img2)
        l, t, r, b = tmp_draw2.textbbox((0, 0), "Ag", font=info_font)
        single_h = b - t
        custom_line_spacing_px = max(0, int(metadata_line_height - single_h))
        meta_pad = int(10 * scale)

        if cmyk_mode:
            bg_fill = (0, 0, 0, 1)  # CMYK white
            bg_outline = (0, 0, 0, 255)  # 100% black
            text_fill = (0, 0, 0, 255)  # K-only text
        else:
            bg_fill = bg_rgb
            bg_outline = bg_outline_rgb
            text_fill = (0, 0, 0)

        if exclude_file_path is False:
            last_parts = Path(file_path).parts[-3:]
            short_path = "/".join(last_parts)
            filename = Path(file_path).name
            # Truncate filename if longer than 25 characters
            # And if we have one of those huge unwieldly filenames that
            # Instagram produces, just show the last two parts of the file path
            if len(filename) > 50:
                filename = f"{filename[:25]}...{filename[-25:]}"
                short_path = "/".join(last_parts[:-1])
            # Draw the short path (excluding filename) above the filename
            if len(last_parts) > 1:
                draw.text((width//2, outer_padding + header_height + metadata_top_margin), short_path, fill=text_black, font=info_font, anchor="mm")
                draw.text((width//2, outer_padding + header_height + metadata_top_margin + metadata_line_height), filename, fill=text_black, font=info_font, anchor="mm")
                y_offset = metadata_line_height * 2 + 5
            else:
                draw.text((width//2, outer_padding + header_height + metadata_top_margin), filename, fill=text_black, font=info_font, anchor="mm")
                y_offset = metadata_line_height + 5
            logging.debug(f"File Path is {short_path}")
            logging.debug(f"Last Parts is {last_parts} and it is {len(last_parts)} elements long")
        draw_text_box(
            draw,
            custom_metadata_text,
            info_font,
            box=(outer_padding, outer_padding + header_height + metadata_top_margin + y_offset, content_area_width_for_wrap, metadata_height),
            padding=meta_pad,
            line_spacing=custom_line_spacing_px,
            align="left",
            v_align="top",
            fill=text_fill,
            background_fill=bg_fill,
            background_radius=int(3 * scale),
            background_outline=bg_outline,
            background_outline_width=1,
        )
        y = outer_padding + header_height + metadata_top_margin + metadata_height + y_offset
    else:
        ################################
        ##                            ##
        ## HERE WE DRAW METADATA TEXT ##
        ##                            ##
        ################################
        for key, value in file_info.items():
            if key.lower() == 'qr_data':
                continue  # Skip QR data in metadata display
            if key.lower() == '_title':
                continue # Skip _title as it's shown in header
            if key.lower() == 'name' or key.lower() == 'filename' or key.lower() == 'filepath' or key.lower() == 'created':
                line = f"{value}"
            elif key.lower() == '_blank':
                line = ""
            elif key.startswith('_'):
                line = f"{value}"

            else:
                line = f"{key}: {value}"
            # Wrap the line to fit within the content area width
            wrapped_lines = wrap_text_by_pixel(draw, line, info_font, content_area_width_for_wrap - avatar_size)
            for wrapped_line in wrapped_lines:
                if avatar_img is not None and y < (avatar_y_coordinate + avatar_size):
                    draw.text((avatar_x_coordinate + avatar_size + meta_pad, y), wrapped_line, fill=text_black, font=info_font, anchor="lt")
                    y += metadata_line_height
                else:
                    draw.text((outer_padding, y), wrapped_line, fill=text_black, font=info_font, anchor="lt")
                    y += metadata_line_height

    # Make sure the preview area starts below the last metadata line
    preview_box_top = max(preview_box_top, int(y + spacing_between_metadata_and_content_preview))
    preview_box_height = preview_box_bottom - preview_box_top - preview_box_padding * 2
    max_preview_lines = max(1, preview_box_height // line_height)

    y = preview_box_top
    ###
    ###
    ### Here we draw the preview box
    ###
    ###
    draw.rectangle(
        [preview_box_left, preview_box_top, preview_box_right, preview_box_bottom],
        fill=preview_background_color,
        outline='black',
        width=1
    )
    # --- Always show preview_lines for .zip, .gz, .bz2 if present ---
    if ext in {'.zip', '.gz', '.bz2'} and preview_lines:
        text_y = preview_box_top + preview_box_padding
        for line in preview_lines:
            if text_y + line_height > preview_box_bottom - preview_box_padding:
                break

        if '\n' in line:
            draw.text((preview_box_left + preview_box_padding, text_y), line, fill='black', font=preview_font)
        else:
            draw.text((preview_box_left + preview_box_padding, text_y), line, fill='black', font=preview_font, anchor="lt")

            text_y += line_height
        return img
    # FIT: show GPS map if present, then summary text below
    if ext == '.fit' and fit_gps_thumb is not None:
        img_w, img_h = fit_gps_thumb.size
        box_w = preview_box_right - preview_box_left - preview_box_padding * 2
        box_h = preview_box_height - preview_box_padding * 2
        x0 = preview_box_left + preview_box_padding + max(0, (box_w - img_w)//2)
        y0 = preview_box_top + preview_box_padding + max(0, (box_h - img_h)//2)
        fit_gps_thumb = scale_image(fit_gps_thumb, 0.95)
        img.paste(fit_gps_thumb, (int(x0), int(y0)))
        # Draw summary below the map if space allows
        try:
            fit_font = ImageFont.truetype("/Users/julian/OMATA Dropbox/Julian Bleecker/PRODUCTION ASSETS/FONTS/3270/3270NerdFontMono-Regular.ttf", 12)
        except:
            fit_font = ImageFont.load_default()
        text_y = y0 + img_h + 10
        for line in preview_lines:
            if text_y + line_height > preview_box_bottom - preview_box_padding:
                break
            if '\n' in line:
                draw.text((preview_box_left + preview_box_padding, text_y), line, fill='black', font=fit_font)
            else:
                draw.text((preview_box_left + preview_box_padding, text_y), line, fill='black', font=fit_font, anchor="lt")
            text_y += line_height
        return img
    # If no GPS map, just show summary text as before
    if ext == '.fit' and preview_lines:
        try:
            fit_font = ImageFont.truetype("/Users/julian/OMATA Dropbox/Julian Bleecker/PRODUCTION ASSETS/FONTS/3270/3270NerdFontMono-Regular.ttf", 12)
        except:
            fit_font = ImageFont.load_default()
        text_y = preview_box_top + preview_box_padding
        for line in preview_lines:
            if text_y + line_height > preview_box_bottom - preview_box_padding:
                break
            draw.text((preview_box_left + preview_box_padding, text_y), line, fill='black', font=fit_font, anchor="lt")
            text_y += line_height
        return img
    # All other previews (images, pdfs, videos, etc.)
    if pdf_grid_thumb is not None:
        img_w, img_h = pdf_grid_thumb.size
        box_w = preview_box_right - preview_box_left - preview_box_padding * 2
        box_h = preview_box_height - preview_box_padding * 2
        x0 = preview_box_left + preview_box_padding + max(0, (box_w - img_w)//2)
        y0 = preview_box_top + preview_box_padding + max(0, (box_h - img_h)//2)
        img.paste(pdf_grid_thumb, (int(x0), int(y0)))
    elif gpx_thumb is not None:
        img_w, img_h = gpx_thumb.size
        box_w = preview_box_right - preview_box_left - preview_box_padding * 2
        box_h = preview_box_height - preview_box_padding * 2
        x0 = preview_box_left + preview_box_padding + max(0, (box_w - img_w)//2)
        y0 = preview_box_top + preview_box_padding + max(0, (box_h - img_h)//2)
        img.paste(gpx_thumb, (int(x0), int(y0)))
    elif video_thumb_grid is not None:
        # Paste the overview thumbnail into the preview area on the base card (which already has header+metadata)
        img_w, img_h = video_thumb_grid.size
        box_w = preview_box_right - preview_box_left - preview_box_padding * 2
        box_h = preview_box_height - preview_box_padding * 2
        x0 = preview_box_left + preview_box_padding + max(0, (box_w - img_w)//2)
        y0 = preview_box_top + preview_box_padding + max(0, (box_h - img_h)//2)
        img.paste(video_thumb_grid, (int(x0), int(y0)))

        if video_frame_thumbs:
            dpi = 300
            overview_img = img.copy()
            draw_frame = ImageDraw.Draw(overview_img)
            min_border_px = int(border_inch_width * dpi)
            color_border_width = min_border_px
            if cmyk_mode:
                draw_frame.rectangle([0, 0, width, height], outline=rgb_to_cmyk(*border_color), width=color_border_width)
            else:
                draw_frame.rectangle([0, 0, width, height], outline=border_color, width=color_border_width)
            # Always produce an overview card
            if not include_video_frames:
                return overview_img
            # Otherwise, build list: overview first, then one per frame
            cards = [overview_img]
            for frame_thumb in video_frame_thumbs:
                frame_w, frame_h = frame_thumb.size
                frame_x0 = preview_box_left + preview_box_padding + max(0, (box_w - frame_w)//2)
                frame_y0 = preview_box_top + preview_box_padding + max(0, (box_h - frame_h)//2)
                frame_img = img.copy()
                # Clear the preview area before placing an individual frame
                draw_frame = ImageDraw.Draw(frame_img)
                draw_frame.rectangle(
                    [preview_box_left + preview_box_padding, preview_box_top + preview_box_padding,
                     preview_box_right - preview_box_padding, preview_box_bottom - preview_box_padding],
                    fill=preview_background_color
                )
                frame_img.paste(frame_thumb, (int(frame_x0), int(frame_y0)))
                # Add border around the frame card
                dpi = 300
                min_border_px = int(border_inch_width * dpi)
                color_border_width = min_border_px
                if cmyk_mode:
                    draw_frame.rectangle([0, 0, width, height], outline=rgb_to_cmyk(*border_color), width=color_border_width)
                else:
                    draw_frame.rectangle([0, 0, width, height], outline=border_color, width=color_border_width)
                cards.append(frame_img)
            return cards
    elif image_thumb is not None:
        ###
        ### HERE WE PASTE THE IMAGE THUMBNAIL
        ###
        
        box_w = preview_box_right - preview_box_left - preview_box_padding * 2
        box_h = preview_box_height - preview_box_padding * 2
        
        image_thumb = ImageOps.contain(image_thumb, (box_w, box_h), Image.LANCZOS)
        img_w, img_h = image_thumb.size
        
        x0 = preview_box_left + preview_box_padding + max(0, (box_w - img_w)//2)
        y0 = preview_box_top + preview_box_padding + max(0, (box_h - img_h)//2)
        logging.debug(f"Pasting image thumbnail at: x={x0}, y={y0}, size={img_w}x{img_h}")
        
        img.paste(image_thumb, (int(x0), int(y0)))
    elif fit_gps_thumb is not None:
        img_w, img_h = fit_gps_thumb.size
        box_w = preview_box_right - preview_box_left - preview_box_padding * 2
        box_h = preview_box_height - preview_box_padding * 2
        x0 = preview_box_left + preview_box_padding + max(0, (box_w - img_w)//2)
        y0 = preview_box_top + preview_box_padding + max(0, (box_h - img_h)//2)
        img.paste(fit_gps_thumb, (int(x0), int(y0)))
    elif zip_file_list is not None:
        text_y = preview_box_top + preview_box_padding
        for line in zip_file_list:
            if text_y + line_height > preview_box_bottom - preview_box_padding:
                break

        if '\n' in line:
            draw.text((preview_box_left + preview_box_padding, text_y), line, fill='black', font=preview_font)
        else:
            draw.text((preview_box_left + preview_box_padding, text_y), line, fill='black', font=preview_font, anchor="lt")

            text_y += line_height
        # Always show preview lines for .zip, .gz, .bz2 if present
        if zip_file_preview_lines is not None:
            for line in zip_file_preview_lines:
                if text_y + line_height > preview_box_bottom - preview_box_padding:
                    break
                if '\n' in line:
                    draw.text((preview_box_left + preview_box_padding, text_y), line, fill='black', font=preview_font)
                else:
                    draw.text((preview_box_left + preview_box_padding, text_y), line, fill='black', font=preview_font, anchor="lt")
                text_y += line_height
        if zip_file_preview_img is not None:
            img_w, img_h = zip_file_preview_img.size
            box_w = preview_box_right - preview_box_left - preview_box_padding * 2
            box_h = preview_box_height - preview_box_padding * 2
            x0 = preview_box_left + preview_box_padding + max(0, (box_w - img_w)//2)
            y0 = text_y + 10
            if y0 + img_h > preview_box_bottom - preview_box_padding:
                img_h = preview_box_bottom - preview_box_padding - y0
                zip_file_preview_img = zip_file_preview_img.crop((0, 0, img_w, img_h))
            img.paste(zip_file_preview_img, (int(x0), int(y0)))
    else:
        text_y = preview_box_top + preview_box_padding
        for line in preview_lines:
            if text_y + line_height > preview_box_bottom - preview_box_padding:
                break
            if '\n' in line:
                draw.text((preview_box_left + preview_box_padding, text_y), line, fill='black', font=preview_font)
            else:
                draw.text((preview_box_left + preview_box_padding, text_y), line, fill='black', font=preview_font, anchor="lt")
            text_y += line_height
    
    
    # I need to convert from RGB to CMYK
    dpi = 300  # or whatever your output DPI is
    #border_inch_width = 0.125  # Minimum border in inches
    min_border_px = int(border_inch_width * dpi)  # 0.125 * 300 = 37 pixels

    color_border_width = min_border_px #max(min_border_px, int(10 * scale), 20)
    
    # color_border_width = min(int(20 * scale), 20)  # Scales with 'scale', but never exceeds 15
    draw.rectangle([0, 0, width, height], outline=rgb_to_cmyk(*border_color), width=color_border_width)
    return img

def determine_file_type(file_path):
    """Categorize files into different types for appropriate rendering."""
    ext = file_path.suffix.lower()
    # Define file type groups with their extensions and icons
    for group, info in FILE_TYPE_GROUPS.items():
        if ext in info['extensions']:
            return group
    
    # Default to "other" for anything not recognized
    return "other"

def get_slack_user_name(slack_user_id, users_json_path):
    """Get the Slack user name for a given user ID from the users.json file."""
    if not slack_user_id or not users_json_path.exists():
        return None
    try:
        with open(users_json_path, 'r', encoding='utf-8', errors='ignore') as uf:
            users = json.load(uf)
        for user in users:
            if user.get('id') == slack_user_id or user.get('name') == slack_user_id:
                return user.get('real_name') or user.get('profile', {}).get('real_name') or user.get('name')
    except Exception as e:
        logging.error(f"Error reading users.json: {e}")
    return None

def save_card_as_tiff(img, output_path, cmyk_mode=False):
    """
    Save a card image as a TIFF file with proper handling for CMYK mode.
    This function ensures borders are preserved during CMYK conversion.
    
    Args:
        img: The PIL Image object to save
        output_path: The path where the TIFF should be saved
        cmyk_mode: Whether to save in CMYK mode (True) or RGB mode (False)
    """
    try:
        if cmyk_mode:
            # For CMYK mode, we need to make sure the border is even more pronounced
            # Draw an additional solid border around the entire image
            draw = ImageDraw.Draw(img)
            #w, h = img.size
            # for i in range(0, 5):  # Draw 5 concentric borders for visibility
            #     draw.rectangle(
            #         [i, i, w-1-i, h-1-i],
            #         outline=(0, 0, 0, 100),  # Solid black in CMYK
            #         width=4  # Thick line
            #     )
            
            # Save with LibTIFF and specific compression settings
            img.save(
                output_path, 
                format='TIFF',
                compression='none',  # No compression for maximum quality
                dpi=(300, 300)       # Set DPI to 300
            )
            logging.info(f"Saved CMYK TIFF with reinforced border: {output_path}")
            logging.info(f"{output_path}")
        else:
            # For RGB mode, add a clear border too
            draw = ImageDraw.Draw(img)
            w, h = img.size
            draw.rectangle([0, 0, w-1, h-1], outline=(0, 0, 0), width=5)
            
            # Standard save
            img.save(output_path, format='TIFF', compression='tiff_deflate')
            logging.info(f"Saved RGB TIFF with reinforced border: {output_path}")
            logging.info(f"{output_path}")

    except Exception as e:
        logging.error(f"Error saving TIFF image: {e}")
        # Fall back to basic save method
        img.save(output_path)
        logging.warning(f"Used fallback save method for: {output_path}")

def process_pdf_or_ai_page(page, max_width, max_height):
    """
    Takes a PIL Image (PDF or AI page), rotates if landscape, and scales to fit the preview box.
    Returns the processed image.
    """
    img_w, img_h = page.size
    # Rotate if landscape
    if img_w > img_h:
        page = page.rotate(90, expand=True)
        img_w, img_h = page.size
    # Scale to fit preview box
    scale_factor = min(max_width / img_w, max_height / img_h, 1) * 0.95
    new_w = int(img_w * scale_factor)
    new_h = int(img_h * scale_factor)
    return page.resize((new_w, new_h), Image.LANCZOS)

def get_excel_preview(file_path, max_rows=10, max_cols=8):
    ext = file_path.suffix.lower()
    preview_lines = []
    try:
        if ext == '.xlsx':
            import openpyxl
            wb = openpyxl.load_workbook(file_path, read_only=True, data_only=True)
            sheet = wb.active
            for i, row in enumerate(sheet.iter_rows(values_only=True)):
                if i >= max_rows:
                    break
                row_str = " | ".join(str(cell) if cell is not None else "" for cell in row[:max_cols])
                preview_lines.append(row_str)
        elif ext == '.xls':
            import xlrd
            wb = xlrd.open_workbook(file_path)
            sheet = wb.sheet_by_index(0)
            for i in range(min(max_rows, sheet.nrows)):
                row = sheet.row_values(i)
                row_str = " | ".join(str(cell) if cell is not None else "" for cell in row[:max_cols])
                preview_lines.append(row_str)
        else:
            preview_lines = ["Unsupported Excel format."]
    except Exception as e:
        preview_lines = [f"Excel preview error: {e}"]
    return preview_lines

def is_probably_html(file_path, max_bytes=262144):
    """
    Heuristic check whether a file's contents look like HTML.
    Reads up to `max_bytes` from the file and looks for common HTML markers.
    """
    try:
        with open(file_path, "rb") as f:
            chunk = f.read(max_bytes)
        try:
            text = chunk.decode("utf-8", errors="ignore")
        except Exception:
            text = chunk.decode("latin-1", errors="ignore")
        lower = text.lower()
        # Strong signals
        if "<!doctype" in lower or "<html" in lower or "<head" in lower or "<body" in lower:
            return True
        # Common tags
        tags = ["<div", "<span", "<p", "<a ", "<meta", "<script", "<title", "<link", "<!doctype"]
        tag_count = sum(1 for t in tags if t in lower)
        if tag_count >= 2:
            return True
        # Generic tag density heuristic
        lt = lower.count("<")
        gt = lower.count(">")
        if lt > 5 and gt > 5 and re.search(r"<[a-z][\s>/]", lower):
            return True
        return False
    except Exception:
        return False

def render_html_to_text(file_path, max_bytes=262144, max_chars=10000, prefer_markdown=True):
    """
    Convert HTML file contents to readable text (or Markdown when html2text is available).
    - Reads up to max_bytes from the file.
    - Strips scripts/styles before conversion.
    - Returns a truncated string no longer than max_chars.
    """
    try:
        with open(file_path, "rb") as f:
            raw = f.read(max_bytes)
        try:
            html = raw.decode("utf-8", errors="ignore")
        except Exception:
            html = raw.decode("latin-1", errors="ignore")

        # Remove script/style blocks first
        html = re.sub(r"(?is)<script.*?>.*?</script>", "", html)
        html = re.sub(r"(?is)<style.*?>.*?</style>", "", html)

        # Prefer html2text -> Markdown if available and requested
        try:
            if prefer_markdown:
                import html2text  # optional dependency
                h = html2text.HTML2Text()
                h.ignore_images = True
                h.ignore_links = False
                h.body_width = 0
                md = h.handle(html)
                result = md.strip()
            else:
                raise ImportError
        except Exception:
            # Fallback: BeautifulSoup to plain text if available
            try:
                from bs4 import BeautifulSoup
                soup = BeautifulSoup(html, "html.parser")
                # remove any remaining script/style tags defensively
                for s in soup(["script", "style"]):
                    s.decompose()
                text = soup.get_text(separator="\n")
                # Collapse multiple blank lines
                result = re.sub(r"\n{3,}", "\n\n", text).strip()
            except Exception:
                # Very conservative fallback: strip tags with regex
                text = re.sub(r"(?is)<[^>]+>", "", html)
                result = re.sub(r"\s{2,}", " ", text).strip()

        # Truncate to max_chars and return
        if len(result) > max_chars:
            return result[:max_chars].rstrip() + "\n\n[truncated]"
        return result
    except Exception:
        return ""


def rgb_to_cmyk(r, g, b):
    if r == 0 and g == 0 and b == 0:
        return (0, 0, 0, 100)
    c = 255 - r
    m = 255 - g
    y = 255 - b
    k = min(c, m, y)
    c = (c - k) if k < 255 else 0
    m = (m - k) if k < 255 else 0
    y = (y - k) if k < 255 else 0
    return (c, m, y, k)

if __name__ == "__main__":
    import argparse
    from pathlib import Path


    parser = argparse.ArgumentParser(description="Generate debug file cards for given files")
    parser.add_argument("files", nargs="+", help="One or more input files to generate cards for")
    parser.add_argument("--output-dir", default="./cards_out", help="Directory to write generated TIFFs into")
    parser.add_argument("--width", type=int, default=800, help="Card width in pixels")
    parser.add_argument("--height", type=int, default=1000, help="Card height in pixels")
    parser.add_argument("--cmyk", action="store_true", help="Save cards in CMYK mode")
    parser.add_argument("--include-video-frames", action="store_true", help="If a video, include per-frame cards")
    parser.add_argument("--max-video-frames", type=int, default=9, help="Minimum number of video frames to include should it come to that")
    args = parser.parse_args()

    out_dir = Path(args.output_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    for fp in args.files:
        try:
            cards = create_file_info_card(fp, width=args.width, height=args.height, cmyk_mode=args.cmyk, include_video_frames=args.include_video_frames, max_video_frames=args.max_video_frames)
            if isinstance(cards, list):
                for idx, card in enumerate(cards):
                    out_path = out_dir / f"{Path(fp).stem}_{idx}.tiff"
                    save_card_as_tiff(card, str(out_path), cmyk_mode=args.cmyk)
            else:
                out_path = out_dir / f"{Path(fp).stem}.tiff"
                save_card_as_tiff(cards, str(out_path), cmyk_mode=args.cmyk)
            print(f"Saved card(s) for {fp} to {out_dir}")
        except Exception as e:
            logging.error("Error processing %s: %s", fp, e, exc_info=True)
